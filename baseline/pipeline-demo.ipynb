{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b95fcbe-4085-4cb6-8fde-7c4601826387",
   "metadata": {
    "id": "mlhq3qfjqFO2"
   },
   "source": [
    "# Model Risk Pipeline\n",
    "\n",
    "_Initial commit: Anton Markov, 19 November 2021_\n",
    "\n",
    "Основная цель данного ноутбука — построить базовую структуру пайплайна с учетом оптимизации гиперпараметров.\n",
    "\n",
    "Реализована оптимизация через `hyperopt`, в будущем возможно поддержка иных библиотек.\n",
    "\n",
    "__Входные данные:__\n",
    "\n",
    "1. Датасет\n",
    "2. Модель\n",
    "3. Список модулей, которые могут оптимизироваться в качества гиперпараметра\n",
    "\n",
    "__Исходящие данные:__\n",
    "\n",
    "1. Оптимальный набор модулей, согласно `hyperopt`\n",
    "2. Параметры обученной оптимальной модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9abbb-ee51-484f-96b8-192c3474e7ff",
   "metadata": {},
   "source": [
    "## 1. Technicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b144269a-e212-4862-bccc-765c1e35f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import umap\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from hyperopt import hp\n",
    "# from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# import umap # does not work for me, since I installed umap instaed of umap-learn by mistake\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# for HyperOpt class\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "# новый пакет!\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "from typing import List, Union\n",
    "from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "from feature_engine.validation import _return_tags\n",
    "from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from feature_engine.selection  import SelectByShuffling\n",
    "from feature_engine.selection  import RecursiveFeatureAddition\n",
    "from feature_engine.selection  import SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2550a6d-604b-4c7c-9929-0d9365b10eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ac53db-2b8f-45b7-b253-509fa7045915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y, y_pred):\n",
    "    res = roc_auc_score(y, y_pred) * 2 - 1\n",
    "    print(f\"Gini: {res}\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead6d70f-f723-4f54-bf97-58153affb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_params(params, pipe):\n",
    "    '''\n",
    "    From all input parameters filter only\n",
    "    those that are relevant for the current\n",
    "    pipeline\n",
    "    '''\n",
    "    pipe_steps = list(pipe.named_steps.keys())\n",
    "    params_keys = list(params.keys())\n",
    "    \n",
    "    return {\n",
    "        key: params[key]\n",
    "        for key in params_keys\n",
    "        if key.split('__')[0] in pipe_steps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d555e819-4f9b-481e-a875-7f11be4320f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pipe(steps_dict, modules):\n",
    "    '''\n",
    "    Construct a pipeline given structure\n",
    "    '''\n",
    "    return [(steps_dict[s], modules[steps_dict[s]]) for s in steps_dict if steps_dict[s] != 'skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803cfd20-67df-4759-9f81-ecf91791f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeHPOpt(object):\n",
    "    '''\n",
    "    Класс PipeHPOpt — Pipeline with hyperparameter optimisation\n",
    "    using hyperopt — нацелен на оптимизацию пайплайна как с точки\n",
    "    зрения входящих в него модулей, так и гиперпараметров каждого\n",
    "    из модулей\n",
    "    '''  \n",
    "    def __init__(self, X, y, modules, mode='kfold', n_folds = 5, test_size=.33, seed=42):\n",
    "        '''   \n",
    "        _inputs:\n",
    "        X — train dataset\n",
    "        y — train targets\n",
    "        modules — dict of all modules that might potentially be included into\n",
    "            the pipeline\n",
    "        mode — wither \"kfold\" or \"valid\" (error if other) — sets if X, y will\n",
    "            be subdivided into k cross-validation samples or train/test samples,\n",
    "            respectively. \"kfold\" is default. Key advantage of valid: it returns\n",
    "            the optimal model; in \"kfold\" mode the model should be retrained with\n",
    "            optimal hyperparameters\n",
    "        n_folds — number of folds at cross-validation (5 is default). Applied\n",
    "            only if mode = \"kfold\". Warning added\n",
    "        test_size — test sample % (.33 is default). Applied only if mode = \"valid\". \n",
    "            Warning added\n",
    "        seed — random seed (42 is default)\n",
    "        '''\n",
    "        if (mode != 'kfold') & (mode != 'valid'):\n",
    "            raise ValueError(\"Choose mode 'kfold' or 'valid'\")\n",
    "        if (mode == 'valid') & (n_folds != 5):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default n_folds won't be used since mode == valid!\")\n",
    "        if (mode == 'kfold') & (test_size != .33):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default test_size won't be used since mode == kfold!\")\n",
    "            \n",
    "        self.X       = X\n",
    "        self.y       = y\n",
    "        self.mode    = mode\n",
    "        self.n_folds = n_folds\n",
    "        self.seed    = seed\n",
    "        self.modules = modules\n",
    "        \n",
    "        if mode == 'valid':\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "    def process(self, space, trials, algo, max_evals, fn_name='_pipe'):\n",
    "        '''\n",
    "        _inputs: TBD\n",
    "        \n",
    "        _output:\n",
    "        result: hyperopt weird object of the optimal model representation\n",
    "        trials: info on each of the hyperopt trials\n",
    "        '''\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        self.result = result\n",
    "        self.trials = trials\n",
    "        return result, trials\n",
    "\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        return self.trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        para = self.get_best_params()\n",
    "        pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "        reg = Pipeline(pipe_steps)\n",
    "        for p in pipe_para['set_params']:\n",
    "            try:\n",
    "                reg.set_params({p: para[p]})\n",
    "            except:\n",
    "                pass # repetition, not DRY, think how to delete\n",
    "        return reg.fit(self.X, self.y)\n",
    "    \n",
    "    def _pipe(self, para):\n",
    "        # print(para)\n",
    "        pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "        reg = Pipeline(pipe_steps)\n",
    "        for p in pipe_para['set_params']:\n",
    "            try:\n",
    "                reg.set_params({p: para[p]})\n",
    "            except:\n",
    "                pass\n",
    "        if self.mode == 'kfold':\n",
    "            return self._train_reg_kfold(reg, para)\n",
    "        elif self.mode == 'valid':\n",
    "            return self._train_reg_valid(reg, para)\n",
    "\n",
    "    def _train_reg_valid(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        pred = reg.predict_proba(self.x_test)[:, 1]\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'model': reg, 'params': para, 'status': STATUS_OK}\n",
    "    \n",
    "    def _train_reg_kfold(self, reg, para):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.seed)\n",
    "        losses = []\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_split_train, X_split_test = self.X.iloc[train_index, :], self.X.iloc[test_index, :]\n",
    "            y_split_train, y_split_test = self.y.iloc[train_index, ],  self.y.iloc[test_index, ]\n",
    "            reg.fit(X_split_train, y_split_train)\n",
    "            pred = reg.predict_proba(X_split_test)[:, 1]\n",
    "            loss = para['loss_func'](y_split_test, pred)\n",
    "            losses.append(loss)\n",
    "        return {'loss': np.mean(losses), 'params': para, 'status': STATUS_OK}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020c325-11af-4cfc-9d61-5d2378598fdd",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b36c16-1aa8-41a0-8462-74cfbe7fc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../datasets/01_german/samples/X_train.parquet')\n",
    "y_train = pd.read_parquet('../datasets/01_german/samples/y_train.parquet').target\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test  = pd.read_parquet('../datasets/01_german/samples/X_test.parquet')\n",
    "y_test  = pd.read_parquet('../datasets/01_german/samples/y_test.parquet').target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff79df1-8826-4f05-918e-03652f8a036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/01_german/factors.json') as json_file:\n",
    "    factors_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bcf567-6fb6-455c-8ec6-09028e11e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheq_acc',\n",
       " 'cred_hist',\n",
       " 'purp',\n",
       " 'save_acc',\n",
       " 'empl_t',\n",
       " 'pers_status',\n",
       " 'guarant_flg',\n",
       " 'prop',\n",
       " 'inst_plan',\n",
       " 'house',\n",
       " 'job',\n",
       " 'tel_flg',\n",
       " 'foreign_flg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_dict['cat_vals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58540fea-e6ce-462c-8427-30f443126065",
   "metadata": {},
   "source": [
    "## 3. Define Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773fea9-9067-4d91-a30d-4594eb5a3716",
   "metadata": {},
   "source": [
    "All the modules that might be part of the pipeline should be defined below (or import them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3c5e57-7b87-420b-b5a8-8bcedade03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineWithReferenceFeature_adj():\n",
    "    \"\"\"\n",
    "    Обертка вокруг CombineWithReferenceFeature()\n",
    "    Позволяет не устанавливать параметры\n",
    "    + variables_to_combine\n",
    "    + reference_variables\n",
    "    заранее (иначе не будет работать с OneHotEncoder\n",
    "    и прочими преобразователями данных, а делать это при .fit()\n",
    "    \"\"\"\n",
    "    def __init__(self, operations):\n",
    "        self.operations = operations\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.combinator = CombineWithReferenceFeature(\n",
    "            variables_to_combine = list(X.columns),\n",
    "            reference_variables = list(X.columns),\n",
    "            operations = self.operations\n",
    "        )\n",
    "        self.combinator.fit(X, y)\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return(self.combinator.transform(X))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b6161f-6a9c-456b-8d1f-d512d792c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPCA_adj():\n",
    "    \"\"\"\n",
    "    Обертка нужна, чтобы transform() возвращал\n",
    "    pd.df(), а не np.array() - не все могут в np\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kpca = sklearn.decomposition.KernelPCA(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.kpca.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.kpca.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.kpca.set_params(**kwargs)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61b3218f-55b3-4e2c-bf8a-3717901155f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_adj():\n",
    "    \"\"\"\n",
    "    Обертка нужна, чтобы transform() возвращал\n",
    "    pd.df(), а не np.array() - не все могут в np\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pca = sklearn.decomposition.PCA(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.pca.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.pca.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.pca.set_params(**kwargs)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87482aec-cd2c-49e2-8b70-5952c635d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Isomap_adj():\n",
    "    \"\"\"\n",
    "    Обертка нужна, чтобы transform() возвращал\n",
    "    pd.df(), а не np.array() - не все могут в np\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.isomap = sklearn.manifold.Isomap(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.isomap.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.isomap.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.isomap.set_params(**kwargs)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c653378-0ee0-45dd-8f69-2096890651f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMAP_adj():\n",
    "    \"\"\"\n",
    "    Обертка нужна, чтобы transform() возвращал\n",
    "    pd.df(), а не np.array() - не все могут в np\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.umap = umap.UMAP(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.umap.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.umap.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.umap.set_params(**kwargs)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da037b85-a5e9-4014-862c-51fb591cdce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur_t</th>\n",
       "      <th>cred_amt</th>\n",
       "      <th>inst_to_income</th>\n",
       "      <th>residence_t</th>\n",
       "      <th>age</th>\n",
       "      <th>n_loans</th>\n",
       "      <th>n_depend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>6836</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>2319</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1236</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>5003</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>886</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>18</td>\n",
       "      <td>6458</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>18</td>\n",
       "      <td>2662</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>24</td>\n",
       "      <td>5804</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>12</td>\n",
       "      <td>1484</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>6</td>\n",
       "      <td>932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dur_t  cred_amt  inst_to_income  residence_t  age  n_loans  n_depend\n",
       "0       60      6836               3            4   63        2         1\n",
       "1       21      2319               2            1   33        1         1\n",
       "2        6      1236               2            4   50        1         1\n",
       "3       21      5003               1            4   29        2         1\n",
       "4       12       886               4            2   21        1         1\n",
       "..     ...       ...             ...          ...  ...      ...       ...\n",
       "795     18      6458               2            4   39        2         2\n",
       "796     18      2662               4            3   32        1         1\n",
       "797     24      5804               4            2   27        2         1\n",
       "798     12      1484               2            1   25        1         1\n",
       "799      6       932               3            2   24        1         1\n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[factors_dict['num_vals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dd616a2-fd16-497c-8943-90756ec3349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur_t</th>\n",
       "      <th>cred_amt</th>\n",
       "      <th>inst_to_income</th>\n",
       "      <th>residence_t</th>\n",
       "      <th>age</th>\n",
       "      <th>n_loans</th>\n",
       "      <th>n_depend</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>6836</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.965244</td>\n",
       "      <td>-0.155577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>2319</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.622228</td>\n",
       "      <td>17.156950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1236</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.346588</td>\n",
       "      <td>-3.309277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>5003</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.932839</td>\n",
       "      <td>6.084053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>886</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.222853</td>\n",
       "      <td>-9.523088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>18</td>\n",
       "      <td>6458</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.170094</td>\n",
       "      <td>-0.657529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>18</td>\n",
       "      <td>2662</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.630462</td>\n",
       "      <td>19.633013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>24</td>\n",
       "      <td>5804</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.106764</td>\n",
       "      <td>1.637339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>12</td>\n",
       "      <td>1484</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.844629</td>\n",
       "      <td>7.785877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>6</td>\n",
       "      <td>932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.341065</td>\n",
       "      <td>-9.104889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dur_t  cred_amt  inst_to_income  residence_t  age  n_loans  n_depend  \\\n",
       "0       60      6836               3            4   63        2         1   \n",
       "1       21      2319               2            1   33        1         1   \n",
       "2        6      1236               2            4   50        1         1   \n",
       "3       21      5003               1            4   29        2         1   \n",
       "4       12       886               4            2   21        1         1   \n",
       "..     ...       ...             ...          ...  ...      ...       ...   \n",
       "795     18      6458               2            4   39        2         2   \n",
       "796     18      2662               4            3   32        1         1   \n",
       "797     24      5804               4            2   27        2         1   \n",
       "798     12      1484               2            1   25        1         1   \n",
       "799      6       932               3            2   24        1         1   \n",
       "\n",
       "             0          1  \n",
       "0     3.965244  -0.155577  \n",
       "1     9.622228  17.156950  \n",
       "2    17.346588  -3.309277  \n",
       "3    -2.932839   6.084053  \n",
       "4    13.222853  -9.523088  \n",
       "..         ...        ...  \n",
       "795   3.170094  -0.657529  \n",
       "796   6.630462  19.633013  \n",
       "797  -5.106764   1.637339  \n",
       "798  18.844629   7.785877  \n",
       "799  13.341065  -9.104889  \n",
       "\n",
       "[800 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kPCA = UMAP_adj()\n",
    "kPCA.fit(X_train[factors_dict['num_vals']], y_train)\n",
    "kPCA.transform(X_train[factors_dict['num_vals']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cb7f3-5f8d-4af8-9236-72acc327b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5dd9e7-ab3e-4563-80d6-51635ce17fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054298a9-dca7-4d49-892e-b7ebc7aad974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2260b472-260b-4716-a2b3-eda7e0910baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Union\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "# from feature_engine.validation import _return_tags\n",
    "# from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "class WoEEncoder_adj(BaseCategoricalTransformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        variables: Union[None, int, str, List[Union[str, int]]] = None,\n",
    "        ignore_format: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        if not isinstance(ignore_format, bool):\n",
    "            raise ValueError(\"ignore_format takes only booleans True and False\")\n",
    "\n",
    "        self.variables = _check_input_parameter_variables(variables)\n",
    "        self.ignore_format = ignore_format\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Learn the WoE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas dataframe of shape = [n_samples, n_features]\n",
    "            The training input samples.\n",
    "            Can be the entire dataframe, not just the categorical variables.\n",
    "        y: pandas series.\n",
    "            Target, must be binary.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._check_fit_input_and_variables(X)\n",
    "\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        # check that y is binary\n",
    "        if y.nunique() != 2:\n",
    "            raise ValueError(\n",
    "                \"This encoder is designed for binary classification. The target \"\n",
    "                \"used has more than 2 unique values.\"\n",
    "            )\n",
    "\n",
    "        temp = pd.concat([X, y], axis=1)\n",
    "        temp.columns = list(X.columns) + [\"target\"]\n",
    "\n",
    "        # if target does not have values 0 and 1, we need to remap, to be able to\n",
    "        # compute the averages.\n",
    "        if any(x for x in y.unique() if x not in [0, 1]):\n",
    "            temp[\"target\"] = np.where(temp[\"target\"] == y.unique()[0], 0, 1)\n",
    "\n",
    "        self.encoder_dict_ = {}\n",
    "\n",
    "        total_pos = temp[\"target\"].sum()\n",
    "        total_neg = len(temp) - total_pos\n",
    "        temp[\"non_target\"] = np.where(temp[\"target\"] == 1, 0, 1)\n",
    "\n",
    "        for var in self.variables_:\n",
    "            pos = (temp.groupby([var])[\"target\"].sum() + .5) / total_pos\n",
    "            neg = (temp.groupby([var])[\"non_target\"].sum() + .5) / total_neg\n",
    "\n",
    "            t = pd.concat([pos, neg], axis=1)\n",
    "            t[\"woe\"] = np.log(t[\"target\"] / t[\"non_target\"])\n",
    "\n",
    "            # we make an adjustment to override this error\n",
    "            # if (\n",
    "            #     not t.loc[t[\"target\"] == 0, :].empty\n",
    "            #     or not t.loc[t[\"non_target\"] == 0, :].empty\n",
    "            # ):\n",
    "            #     raise ValueError(\n",
    "            #         \"The proportion of one of the classes for a category in \"\n",
    "            #         \"variable {} is zero, and log of zero is not defined\".format(var)\n",
    "            #     )\n",
    "\n",
    "            self.encoder_dict_[var] = t[\"woe\"].to_dict()\n",
    "\n",
    "        self._check_encoding_dictionary()\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Ugly work around to import the docstring for Sphinx, otherwise not necessary\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    transform.__doc__ = BaseCategoricalTransformer.transform.__doc__\n",
    "\n",
    "    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().inverse_transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    inverse_transform.__doc__ = BaseCategoricalTransformer.inverse_transform.__doc__\n",
    "\n",
    "    def _more_tags(self):\n",
    "        tags_dict = _return_tags()\n",
    "        # in the current format, the tests are performed using continuous np.arrays\n",
    "        # this means that when we encode some of the values, the denominator is 0\n",
    "        # and this the transformer raises an error, and the test fails.\n",
    "        # For this reason, most sklearn transformers will fail. And it has nothing to\n",
    "        # do with the class not being compatible, it is just that the inputs passed\n",
    "        # are not suitable\n",
    "        tags_dict[\"_skip_test\"] = True\n",
    "        return tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22dc81ed-dce6-4a74-a8cd-549a82b69ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WoE_module = WoEEncoder_adj(variables = factors_dict['cat_vals'])\n",
    "\n",
    "OneHot_module = OneHotEncoder(variables = factors_dict['cat_vals'])\n",
    "\n",
    "PCA_module = PCA_adj(\n",
    "    n_components = 2,    # сколько оставить компонентов; по дефолту - все\n",
    "    whiten = False,      # отключаем whitening - декорреляцию фичей\n",
    "    svd_solver = \"full\", # детали SVD преобразования, за подробностями см. доки\n",
    ")\n",
    "\n",
    "kPCA_module = KernelPCA_adj(\n",
    "    n_components = 8,  # сколько оставить компонентов; по дефолту - все\n",
    "    kernel = \"linear\", # ядро. По дфеолту линейное. Можно сделать своё, но тогда его нужно предварительно вычислить отдельно,\n",
    "                       # поставить kernel = \"precomputed\" и передать уже вычисленное ядро в качестве X\n",
    "    degree = 3,        # степень полинома для некоторых типов ядер. Важный параметр для тьюнинга, но сильно напрягает процессор\n",
    "    n_jobs = -1        # объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "Isomap_module = Isomap_adj(\n",
    "    n_neighbors = 5, #количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2,  #сколько оставить компонент; по дефолту - 2\n",
    "    path_method = \"auto\", #алгоритм, который вычисляет кратчайший путь. Варианты см. на странице функции. Этот подбирает сам.\n",
    "    neighbors_algorithm = \"auto\", #алгоритм, который ищет соседей. Инстанс класса NearestNeighbours\n",
    "    n_jobs = -1 #объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "UMAP_module = UMAP_adj(\n",
    "    n_neighbors = 5,  # количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2, # сколько оставить компонентов; по дефолту - 2\n",
    "    min_dist = 0.1    # минимальная дистанция, которую можно сохранять между точками в получающемся пространстве. Гиперпараметр. При увеличении начинает лучше улавливать общую структуру, но хуже - локальную\n",
    ")\n",
    "\n",
    "CombWRef_module = CombineWithReferenceFeature_adj(\n",
    "    operations = ['mul']\n",
    ")\n",
    "\n",
    "lgbm_mdl = LGBMClassifier(\n",
    "    num_leaves = 10,\n",
    "    learning_rate = .1,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda = 8,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# Tackling imbalances in target\n",
    "RUS_module    = RandomUnderSampler(random_state = seed)\n",
    "ROS_module    = RandomOverSampler(random_state = seed)\n",
    "SMOTE_module  = SMOTE(random_state = seed)\n",
    "ADASYN_module = ADASYN(random_state = seed)\n",
    "\n",
    "# feature selection\n",
    "SeqFearSel_module = SequentialFeatureSelector(\n",
    "    estimator  = lgbm_mdl,  \n",
    "    # k_features = 5,                                                  \n",
    "    forward    = True,                                                  \n",
    "    floating   = True,                                                \n",
    "    verbose    = 0,\n",
    "    cv         = 5\n",
    ")\n",
    "RecFeatAdd_module = RecursiveFeatureAddition(\n",
    "    lgbm_mdl,\n",
    "    threshold = 0.005\n",
    ")\n",
    "# SelShuffl_module = SelectByShuffling(\n",
    "#     estimator = lgbm_mdl,\n",
    "#     # variables=X.columns.to_list(),                                      # можно задать подмножество\n",
    "#     scoring='roc_auc',                                                  # метрика\n",
    "#     threshold=0.01,                                                     # порог ее снижения\n",
    "#     cv=5,\n",
    "#     random_state=42\n",
    "# )\n",
    "SmartSel_module = SmartCorrelatedSelection(\n",
    "    # variables=X.columns.to_list(),\n",
    "    method=\"pearson\",                # можно взять свою функцию\n",
    "    threshold=0.3,                   # порог корреляции\n",
    "    selection_method=\"variance\",     # из коррелирующих групп выбираем признак с наиб дисперсией\n",
    "    estimator=None,                  # понадобится для selection_method=\"model_performance\"        \n",
    "    cv=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0d23e-0fe4-4b32-b194-4b85d2fd3332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b1fe13d-1aed-4443-88b9-75fa746be5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WoE_module = WoEEncoder_adj()\n",
    "\n",
    "# X_test = pd.DataFrame([\n",
    "#     ['foo', 'bar', 'foo', 'bar', 'foo', 'foo', 'bar', 'foo', 'foo', 'bar'],\n",
    "#     ['test', 'test', 'test2', 'test2', 'test2', 'test', 'test', 'test', 'test', 'test2']\n",
    "# ]).T\n",
    "# X_test.columns = ['col1', 'col2']\n",
    "# y_test = pd.Series([1, 0, 1, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "# WoE_module.fit(X_test, y_test)\n",
    "\n",
    "# pd.concat([X_test, y_test, WoE_module.transform(X_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a11794-cfd5-44e9-a7c8-afb8a131ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "\n",
    "# events = 6\n",
    "# non_events = 4\n",
    "# foo_events = 4 + .1\n",
    "# foo_non_events = 2 + .1\n",
    "\n",
    "# np.log((foo_events / events) / (foo_non_events / non_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12046c50-6419-41a5-add4-99f4329eda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'WoE':         WoE_module,\n",
    "    'OneHot':      OneHot_module,\n",
    "    'PCA':         PCA_module,\n",
    "    'kPCA':        kPCA_module,\n",
    "    'Isomap':      Isomap_module,\n",
    "    'UMAP':        UMAP_module,\n",
    "    'CombWRef':    CombWRef_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    'lgbm':        lgbm_mdl,\n",
    "    'RUS':         RUS_module,      \n",
    "    'ROS':         ROS_module,      \n",
    "    'SMOTE':       SMOTE_module,  \n",
    "    'ADASYN':      ADASYN_module,\n",
    "    'SeqFearSel':  SeqFearSel_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    # 'SelShuffl':   SelShuffl_module,\n",
    "    'SmartSel':    SmartSel_module    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9191776-4f78-43dc-aa59-162abcb164d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Define Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb5e9c-b033-4ce9-a5eb-113692201e73",
   "metadata": {},
   "source": [
    "Статья с примером [здесь](https://towardsdatascience.com/an-example-of-hyperparameter-optimization-on-xgboost-lightgbm-and-catboost-using-hyperopt-12bc41a271e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcacdc-9228-4db2-b546-25700f07e8e6",
   "metadata": {},
   "source": [
    "Определим структуру самого пайплайна. Словесное описание:\n",
    "    \n",
    "1. Энкодинг категориальных переменных:\n",
    "    + OneHotEncoder\n",
    "    + WoE\n",
    "3. Feature Engineering:\n",
    "    + PCA\n",
    "    + Kernel PCA\n",
    "    + Isomap\n",
    "    + UMAP\n",
    "    + _отсутствует_\n",
    "4. Feature Selection:\n",
    "    + RecursiveFeatureAddition\n",
    "    + _отсутствует_\n",
    "4. Resampling:\n",
    "    + Randomised Undersampling (RUS)\n",
    "    + Randomised Oversampling  (ROS)\n",
    "    + Synthetic Minority Oversampling Technique (SMOTE)\n",
    "    + Adaptive Synthetic (ADASYN)\n",
    "    + _отсутствует_\n",
    "5. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda1a09-9ad5-480d-b1ef-7ecdeaa21774",
   "metadata": {},
   "source": [
    "А так это будет выражаться в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af3a5d1-d094-4acd-a218-a6e3839928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cat_encoding':  hp.choice('cat_encoding', ['OneHot', 'WoE']), # , 'woe' пропустить нельзя из-за наличия кат. пер-х\n",
    "    'feat_eng':      hp.choice('feat_eng',     ['skip', 'PCA', 'kPCA', 'Isomap', 'UMAP']), # , 'CombWRef' # удалил, т.к. долго считается\n",
    "    'feat_sel':      hp.choice('feat_sel',     ['skip', 'SeqFearSel', 'RecFeatAdd', 'SmartSel']), # 'SelShuffl' is omitted, since it might drop all Xs\n",
    "    'imbalance':     hp.choice('imbalance',    ['skip', 'RUS', 'ROS', 'SMOTE', 'ADASYN']),\n",
    "    'lgbm':          'lgbm'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9529da0-a54b-46ee-b43b-b6f5a14b4705",
   "metadata": {},
   "source": [
    "Заметим, что 'skip' позволяет игнорировать соответствующий шаг в пайплайне. Названия типа `\"onehot\"` должны совпадать с названиями в словаре `modules`, который мы определили на Шаге 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1b7ab-92ba-4154-9936-c218e70f8dbf",
   "metadata": {},
   "source": [
    "В следующий словарь добавляем гиперпараметры каждого из модулей, которые мы хотим оптимизировать. Названия строятся следующи образом:\n",
    "\n",
    "`<Название модуля>__<название параметра>`\n",
    "\n",
    "Например, чтобы задать параметр `num_leaves` модуля lgbm, трубуется добваить значение с ключем `lgbm__num_leaves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b710156-03b3-4e15-9b8f-3d1056037741",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_params = {\n",
    "    # OneHotEncoder does not need hyperparams\n",
    "    # RecFeatAdd might be redefined to receive a correct estimator\n",
    "    # PCA\n",
    "    'PCA__n_components':      hp.choice('PCA__n_components',      np.arange(2, 11)),\n",
    "    'PCA__whiten':            hp.choice('PCA__whiten',            [True, False]),\n",
    "    'PCA__svd_solver':        hp.choice('PCA__svd_solver',        ['full', 'arpack', 'auto', 'randomized']),\n",
    "    \n",
    "    # kPCA\n",
    "    'kPCA__n_components':     hp.choice('kPCA__n_components',     np.arange(5, 11)),\n",
    "    'kPCA__kernel':           hp.choice('kPCA__kernel',           ['linear', 'poly', 'rbf', 'sigmoid', 'cosine', 'precomputed']),\n",
    "    \n",
    "    # Isomap\n",
    "    'Isomap__n_neighbors':    hp.choice('Isomap__n_neighbors',    np.arange(2, 11)),\n",
    "    'Isomap__n_components':   hp.choice('Isomap__n_components',   np.arange(2, 5)),\n",
    "    'Isomap__path_method':    hp.choice('Isomap__path_method',    ['auto', 'FW', 'D']),\n",
    "    \n",
    "    # UMAP\n",
    "    'UMAP__n_neighbors':      hp.choice('UMAP__n_neighbors',      np.arange(2, 11)),\n",
    "    'UMAP__n_components':     hp.choice('UMAP__n_components',     np.arange(2, 11)),\n",
    "    'UMAP__min_dist':         hp.choice('UMAP__min_dist',         np.arange(0.05, 1, 0.05)),\n",
    "    \n",
    "    # LightGBM\n",
    "    'lgbm__learning_rate':    hp.choice('lgbm__learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'lgbm__num_leaves':       hp.choice('lgbm__num_leaves',       np.arange(5, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_alpha':        hp.choice('lgbm__reg_alpha',        np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_lambda':       hp.choice('lgbm__reg_lambda',       np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__n_estimators':     100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e087a-0d3e-45ab-95a4-51dfa65d4fe0",
   "metadata": {},
   "source": [
    "Чтобы параметры можно было оптимизировать, модули должны иметь метод `.set_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3d558b4-e575-4e78-9999-72581f265261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technicals — define minimization task\n",
    "pipe_para = dict()\n",
    "pipe_para['pipe_params']    = pipe_params\n",
    "pipe_para['set_params']     = set_params\n",
    "pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.roc_auc_score(y, pred)\n",
    "# pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.log_loss(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35572ab5-126d-4c78-a757-5a423def797f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 10/10 [02:44<00:00, 16.49s/trial, best loss: -0.7763669646161422]\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "hpoptimizer = PipeHPOpt(X_train, y_train, modules=modules, mode='kfold', n_folds = 5, seed=seed)\n",
    "lgb_opt, trials = hpoptimizer.process(space=pipe_para, trials=Trials(), algo=tpe.suggest, max_evals=10)\n",
    "\n",
    "# hpoptimizer = PipeStructHPOpt(X_train, y_train, modules, space_params=set_params, mode='kfold', n_folds = 5, seed=seed)\n",
    "# lgb_opt, trials = hpoptimizer.process(space_steps=steps, trials=Trials(), algo=tpe.suggest, max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739b7ca6-89f8-46a5-8b4c-78a33730fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_func': <function __main__.<lambda>(y, pred)>,\n",
       " 'pipe_params': {'cat_encoding': 'WoE',\n",
       "  'feat_eng': 'PCA',\n",
       "  'feat_sel': 'skip',\n",
       "  'imbalance': 'skip',\n",
       "  'lgbm': 'lgbm'},\n",
       " 'set_params': {'Isomap__n_components': 4,\n",
       "  'Isomap__n_neighbors': 5,\n",
       "  'Isomap__path_method': 'FW',\n",
       "  'PCA__n_components': 9,\n",
       "  'PCA__svd_solver': 'full',\n",
       "  'PCA__whiten': False,\n",
       "  'UMAP__min_dist': 0.15000000000000002,\n",
       "  'UMAP__n_components': 10,\n",
       "  'UMAP__n_neighbors': 7,\n",
       "  'kPCA__kernel': 'sigmoid',\n",
       "  'kPCA__n_components': 8,\n",
       "  'lgbm__learning_rate': 0.3,\n",
       "  'lgbm__n_estimators': 100,\n",
       "  'lgbm__num_leaves': 14,\n",
       "  'lgbm__reg_alpha': 14,\n",
       "  'lgbm__reg_lambda': 8}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpoptimizer.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b71e6259-9a6b-48b3-be5e-afddd7b058a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('WoE',\n",
       "                 WoEEncoder_adj(variables=['cheq_acc', 'cred_hist', 'purp',\n",
       "                                           'save_acc', 'empl_t', 'pers_status',\n",
       "                                           'guarant_flg', 'prop', 'inst_plan',\n",
       "                                           'house', 'job', 'tel_flg',\n",
       "                                           'foreign_flg'])),\n",
       "                ('PCA', <__main__.PCA_adj object at 0x0000029D22369348>),\n",
       "                ('lgbm',\n",
       "                 LGBMClassifier(num_leaves=10, random_state=42, reg_alpha=8,\n",
       "                                reg_lambda=8))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mdl = hpoptimizer.get_best_model()\n",
    "best_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc8832c-8df3-4acb-8535-11dc6a9523ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.7585121623527491\n",
      "Gini: 0.5771126337300156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5771126337300156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gini(y_train, best_mdl.predict_proba(X_train)[:, 1])\n",
    "Gini(y_test, best_mdl.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8a0bc-ce75-46ea-ab7d-62213b73ca58",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933b1a4-9842-4ae4-8da8-2e23d1e61ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_debug = X_train.copy()\n",
    "y_train_debug = y_train.copy()\n",
    "X_train_debug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13f849-5270-49da-991f-565ff6b5e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules['OneHot'].fit(X_train_debug, y_train_debug)\n",
    "X_train_debug = modules['OneHot'].transform(X_train_debug)\n",
    "X_train_debug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f08ec-fc40-47cc-9126-60f40a2ba619",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules['SelShuffl'].set_params(**{'threshold': .01})\n",
    "modules['SelShuffl'].fit(X_train_debug, y_train_debug)\n",
    "len(modules['SelShuffl'].features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9b845-ec66-4a4c-ab10-853dccc754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_debug = modules['SelShuffl'].transform(X_train_debug)\n",
    "X_train_debug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cb23e-66f8-42db-ad49-af2a0a0a4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_debug, y_train_debug = modules['RUS'].fit_resample(X_train_debug, y_train_debug)\n",
    "X_train_debug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def0ae3-77af-49fd-9a59-4b0c7b4b692b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modules['lgbm'].set_params(**{\n",
    "    'learning_rate': 0.2,\n",
    "    'n_estimators': 100,\n",
    "    'num_leaves': 14, \n",
    "    'reg_alpha': 5, \n",
    "    'reg_lambda': 9\n",
    "})\n",
    "modules['lgbm'].fit(X_train_debug, y_train_debug)\n",
    "modules['lgbm'].predict_proba(X_train_debug)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba432b-f5be-4be8-99af-ea5aa45e992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe = Pipeline(\n",
    "    [('OneHot', modules['OneHot']), ('SelShuffl', modules['SelShuffl']), ('RUS', modules['RUS']), ('lgbm', modules['lgbm'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432737b3-fe05-49c1-a942-f24ba535e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe = mdl_pipe.set_params(**{\n",
    "    'lgbm__learning_rate': 0.2,\n",
    "    'lgbm__n_estimators': 100,\n",
    "    'lgbm__num_leaves': 14, \n",
    "    'lgbm__reg_alpha': 5, \n",
    "    'lgbm__reg_lambda': 9\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469933f0-df40-4c5c-8e49-81a4e3dd8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe.fit(X_train_debug, y_train_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e9f77-f844-4da0-ba2e-a522c7e7deba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
