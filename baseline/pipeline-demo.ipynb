{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b95fcbe-4085-4cb6-8fde-7c4601826387",
   "metadata": {
    "id": "mlhq3qfjqFO2"
   },
   "source": [
    "# Model Risk Pipeline\n",
    "\n",
    "_Initial commit: Anton Markov, 19 November 2021_\n",
    "\n",
    "Основная цель данного ноутбука — построить базовую структуру пайплайна с учетом оптимизации гиперпараметров.\n",
    "\n",
    "Реализована оптимизация через `hyperopt`, в будущем возможно поддержка иных библиотек.\n",
    "\n",
    "__Входные данные:__\n",
    "\n",
    "1. Датасет\n",
    "2. Модель\n",
    "3. Список модулей, которые могут оптимизироваться в качества гиперпараметра\n",
    "\n",
    "__Исходящие данные:__\n",
    "\n",
    "1. Оптимальный набор модулей, согласно `hyperopt`\n",
    "2. Параметры обученной оптимальной модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9abbb-ee51-484f-96b8-192c3474e7ff",
   "metadata": {},
   "source": [
    "## 1. Technicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b144269a-e212-4862-bccc-765c1e35f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import umap\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from hyperopt import hp\n",
    "# from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# import umap # does not work for me, since I installed umap instaed of umap-learn by mistake\n",
    "\n",
    "# for HyperOpt class\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "# новый пакет!\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "from typing import List, Union\n",
    "from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "from feature_engine.validation import _return_tags\n",
    "from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from feature_engine.selection  import SelectByShuffling\n",
    "from feature_engine.selection  import RecursiveFeatureAddition\n",
    "from feature_engine.selection  import SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2550a6d-604b-4c7c-9929-0d9365b10eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ac53db-2b8f-45b7-b253-509fa7045915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y, y_pred):\n",
    "    res = roc_auc_score(y, y_pred) * 2 - 1\n",
    "    print(f\"Gini: {res}\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead6d70f-f723-4f54-bf97-58153affb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_params(params, pipe):\n",
    "    '''\n",
    "    From all input parameters filter only\n",
    "    those that are relevant for the current\n",
    "    pipeline\n",
    "    '''\n",
    "    pipe_steps = list(pipe.named_steps.keys())\n",
    "    params_keys = list(params.keys())\n",
    "    \n",
    "    return {\n",
    "        key: params[key]\n",
    "        for key in params_keys\n",
    "        if key.split('__')[0] in pipe_steps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d555e819-4f9b-481e-a875-7f11be4320f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pipe(steps_dict, modules):\n",
    "    '''\n",
    "    Construct a pipeline given structure\n",
    "    '''\n",
    "    return [(steps_dict[s], modules[steps_dict[s]]) for s in steps_dict if steps_dict[s] != 'skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803cfd20-67df-4759-9f81-ecf91791f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeHPOpt(object):\n",
    "    '''\n",
    "    Класс PipeHPOpt — Pipeline with hyperparameter optimisation\n",
    "    using hyperopt — нацелен на оптимизацию пайплайна как с точки\n",
    "    зрения входящих в него модулей, так и гиперпараметров каждого\n",
    "    из модулей\n",
    "    '''  \n",
    "    def __init__(self, X, y, modules, mode='kfold', n_folds = 5, test_size=.33, seed=42):\n",
    "        '''   \n",
    "        _inputs:\n",
    "        X — train dataset\n",
    "        y — train targets\n",
    "        modules — dict of all modules that might potentially be included into\n",
    "            the pipeline\n",
    "        mode — wither \"kfold\" or \"valid\" (error if other) — sets if X, y will\n",
    "            be subdivided into k cross-validation samples or train/test samples,\n",
    "            respectively. \"kfold\" is default. Key advantage of valid: it returns\n",
    "            the optimal model; in \"kfold\" mode the model should be retrained with\n",
    "            optimal hyperparameters\n",
    "        n_folds — number of folds at cross-validation (5 is default). Applied\n",
    "            only if mode = \"kfold\". Warning added\n",
    "        test_size — test sample % (.33 is default). Applied only if mode = \"valid\". \n",
    "            Warning added\n",
    "        seed — random seed (42 is default)\n",
    "        '''\n",
    "        if (mode != 'kfold') & (mode != 'valid'):\n",
    "            raise ValueError(\"Choose mode 'kfold' or 'valid'\")\n",
    "        if (mode == 'valid') & (n_folds != 5):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default n_folds won't be used since mode == valid!\")\n",
    "        if (mode == 'kfold') & (test_size != .33):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default test_size won't be used since mode == kfold!\")\n",
    "            \n",
    "        self.X       = X\n",
    "        self.y       = y\n",
    "        self.mode    = mode\n",
    "        self.n_folds = n_folds\n",
    "        self.seed    = seed\n",
    "        self.modules = modules\n",
    "        \n",
    "        if mode == 'valid':\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "    def process(self, space, trials, algo, max_evals, fn_name='_pipe'):\n",
    "        '''\n",
    "        _inputs: TBD\n",
    "        \n",
    "        _output:\n",
    "        result: hyperopt weird object of the optimal model representation\n",
    "        trials: info on each of the hyperopt trials\n",
    "        '''\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        self.result = result\n",
    "        self.trials = trials\n",
    "        return result, trials\n",
    "\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        return self.trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        para = self.get_best_params()\n",
    "        pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "        reg = Pipeline(pipe_steps)\n",
    "        for p in pipe_para['set_params']:\n",
    "            try:\n",
    "                reg.set_params({p: para[p]})\n",
    "            except:\n",
    "                pass # repetition, not DRY, think how to delete\n",
    "        return reg.fit(self.X, self.y)\n",
    "    \n",
    "    def _pipe(self, para):\n",
    "        # print(para)\n",
    "        pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "        reg = Pipeline(pipe_steps)\n",
    "        for p in pipe_para['set_params']:\n",
    "            try:\n",
    "                reg.set_params({p: para[p]})\n",
    "            except:\n",
    "                pass\n",
    "        if self.mode == 'kfold':\n",
    "            return self._train_reg_kfold(reg, para)\n",
    "        elif self.mode == 'valid':\n",
    "            return self._train_reg_valid(reg, para)\n",
    "\n",
    "    def _train_reg_valid(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        pred = reg.predict_proba(self.x_test)[:, 1]\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'model': reg, 'params': para, 'status': STATUS_OK}\n",
    "    \n",
    "    def _train_reg_kfold(self, reg, para):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.seed)\n",
    "        losses = []\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_split_train, X_split_test = self.X.iloc[train_index, :], self.X.iloc[test_index, :]\n",
    "            y_split_train, y_split_test = self.y.iloc[train_index, ],  self.y.iloc[test_index, ]\n",
    "            reg.fit(X_split_train, y_split_train)\n",
    "            pred = reg.predict_proba(X_split_test)[:, 1]\n",
    "            loss = para['loss_func'](y_split_test, pred)\n",
    "            losses.append(loss)\n",
    "        return {'loss': np.mean(losses), 'params': para, 'status': STATUS_OK}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020c325-11af-4cfc-9d61-5d2378598fdd",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b36c16-1aa8-41a0-8462-74cfbe7fc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../datasets/01_german/samples/X_train.parquet')\n",
    "y_train = pd.read_parquet('../datasets/01_german/samples/y_train.parquet').target\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test  = pd.read_parquet('../datasets/01_german/samples/X_test.parquet')\n",
    "y_test  = pd.read_parquet('../datasets/01_german/samples/y_test.parquet').target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff79df1-8826-4f05-918e-03652f8a036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/01_german/factors.json') as json_file:\n",
    "    factors_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bcf567-6fb6-455c-8ec6-09028e11e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheq_acc',\n",
       " 'cred_hist',\n",
       " 'purp',\n",
       " 'save_acc',\n",
       " 'empl_t',\n",
       " 'pers_status',\n",
       " 'guarant_flg',\n",
       " 'prop',\n",
       " 'inst_plan',\n",
       " 'house',\n",
       " 'job',\n",
       " 'tel_flg',\n",
       " 'foreign_flg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_dict['cat_vals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58540fea-e6ce-462c-8427-30f443126065",
   "metadata": {},
   "source": [
    "## 3. Define Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773fea9-9067-4d91-a30d-4594eb5a3716",
   "metadata": {},
   "source": [
    "All the modules that might be part of the pipeline should be defined below (or import them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3c5e57-7b87-420b-b5a8-8bcedade03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineWithReferenceFeature_adj():\n",
    "    \"\"\"\n",
    "    Обертка вокруг CombineWithReferenceFeature()\n",
    "    Позволяет не устанавливать параметры\n",
    "    + variables_to_combine\n",
    "    + reference_variables\n",
    "    заранее (иначе не будет работать с OneHotEncoder\n",
    "    и прочими преобразователями данных, а делать это при .fit()\n",
    "    \"\"\"\n",
    "    def __init__(self, operations):\n",
    "        self.operations = operations\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.combinator = CombineWithReferenceFeature(\n",
    "            variables_to_combine = list(X.columns),\n",
    "            reference_variables = list(X.columns),\n",
    "            operations = self.operations\n",
    "        )\n",
    "        self.combinator.fit(X, y)\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return(self.combinator.transform(X))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4719df0-4d13-4177-b6f8-1af8f91ffc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionReducer():\n",
    "    \"\"\"\n",
    "    Обертка нужна:\n",
    "    1. Чтобы не заменять фичи, а добавлять их к исходному df\n",
    "    2. Для PCA ouput = np.array, требуется заменить на pd.DataFrame \n",
    "    \"\"\"\n",
    "    def __init__(self, gen_class, **kwargs):\n",
    "        self.reducer = gen_class(**kwargs)\n",
    "        # self.reducer.set_params()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.reducer.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.reducer.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.reducer.set_params(**kwargs)\n",
    "        return self     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2260b472-260b-4716-a2b3-eda7e0910baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Union\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "# from feature_engine.validation import _return_tags\n",
    "# from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "class WoEEncoder_adj(BaseCategoricalTransformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        variables: Union[None, int, str, List[Union[str, int]]] = None,\n",
    "        ignore_format: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        if not isinstance(ignore_format, bool):\n",
    "            raise ValueError(\"ignore_format takes only booleans True and False\")\n",
    "\n",
    "        self.variables = _check_input_parameter_variables(variables)\n",
    "        self.ignore_format = ignore_format\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Learn the WoE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas dataframe of shape = [n_samples, n_features]\n",
    "            The training input samples.\n",
    "            Can be the entire dataframe, not just the categorical variables.\n",
    "        y: pandas series.\n",
    "            Target, must be binary.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._check_fit_input_and_variables(X)\n",
    "\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        # check that y is binary\n",
    "        if y.nunique() != 2:\n",
    "            raise ValueError(\n",
    "                \"This encoder is designed for binary classification. The target \"\n",
    "                \"used has more than 2 unique values.\"\n",
    "            )\n",
    "\n",
    "        temp = pd.concat([X, y], axis=1)\n",
    "        temp.columns = list(X.columns) + [\"target\"]\n",
    "\n",
    "        # if target does not have values 0 and 1, we need to remap, to be able to\n",
    "        # compute the averages.\n",
    "        if any(x for x in y.unique() if x not in [0, 1]):\n",
    "            temp[\"target\"] = np.where(temp[\"target\"] == y.unique()[0], 0, 1)\n",
    "\n",
    "        self.encoder_dict_ = {}\n",
    "\n",
    "        total_pos = temp[\"target\"].sum()\n",
    "        total_neg = len(temp) - total_pos\n",
    "        temp[\"non_target\"] = np.where(temp[\"target\"] == 1, 0, 1)\n",
    "\n",
    "        for var in self.variables_:\n",
    "            pos = (temp.groupby([var])[\"target\"].sum() + .5) / total_pos\n",
    "            neg = (temp.groupby([var])[\"non_target\"].sum() + .5) / total_neg\n",
    "\n",
    "            t = pd.concat([pos, neg], axis=1)\n",
    "            t[\"woe\"] = np.log(t[\"target\"] / t[\"non_target\"])\n",
    "\n",
    "            # we make an adjustment to override this error\n",
    "            # if (\n",
    "            #     not t.loc[t[\"target\"] == 0, :].empty\n",
    "            #     or not t.loc[t[\"non_target\"] == 0, :].empty\n",
    "            # ):\n",
    "            #     raise ValueError(\n",
    "            #         \"The proportion of one of the classes for a category in \"\n",
    "            #         \"variable {} is zero, and log of zero is not defined\".format(var)\n",
    "            #     )\n",
    "\n",
    "            self.encoder_dict_[var] = t[\"woe\"].to_dict()\n",
    "\n",
    "        self._check_encoding_dictionary()\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Ugly work around to import the docstring for Sphinx, otherwise not necessary\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    transform.__doc__ = BaseCategoricalTransformer.transform.__doc__\n",
    "\n",
    "    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().inverse_transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    inverse_transform.__doc__ = BaseCategoricalTransformer.inverse_transform.__doc__\n",
    "\n",
    "    def _more_tags(self):\n",
    "        tags_dict = _return_tags()\n",
    "        # in the current format, the tests are performed using continuous np.arrays\n",
    "        # this means that when we encode some of the values, the denominator is 0\n",
    "        # and this the transformer raises an error, and the test fails.\n",
    "        # For this reason, most sklearn transformers will fail. And it has nothing to\n",
    "        # do with the class not being compatible, it is just that the inputs passed\n",
    "        # are not suitable\n",
    "        tags_dict[\"_skip_test\"] = True\n",
    "        return tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22dc81ed-dce6-4a74-a8cd-549a82b69ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WoE_module = WoEEncoder_adj(variables = factors_dict['cat_vals'])\n",
    "\n",
    "OneHot_module = OneHotEncoder(variables = factors_dict['cat_vals'])\n",
    "\n",
    "PCA_module = DimensionReducer(\n",
    "    gen_class = sklearn.decomposition.PCA,\n",
    "    n_components = 2,    # сколько оставить компонентов; по дефолту - все\n",
    "    whiten = False,      # отключаем whitening - декорреляцию фичей\n",
    "    svd_solver = \"full\", # детали SVD преобразования, за подробностями см. доки\n",
    ")\n",
    "\n",
    "kPCA_module = DimensionReducer(\n",
    "    gen_class = sklearn.decomposition.KernelPCA,\n",
    "    n_components = 8,  # сколько оставить компонентов; по дефолту - все\n",
    "    kernel = \"linear\", # ядро. По дфеолту линейное. Можно сделать своё, но тогда его нужно предварительно вычислить отдельно,\n",
    "                       # поставить kernel = \"precomputed\" и передать уже вычисленное ядро в качестве X\n",
    "    degree = 3,        # степень полинома для некоторых типов ядер. Важный параметр для тьюнинга, но сильно напрягает процессор\n",
    "    n_jobs = -1        # объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "Isomap_module = DimensionReducer(\n",
    "    gen_class = sklearn.manifold.Isomap,\n",
    "    n_neighbors = 5, #количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2,  #сколько оставить компонент; по дефолту - 2\n",
    "    path_method = \"auto\", #алгоритм, который вычисляет кратчайший путь. Варианты см. на странице функции. Этот подбирает сам.\n",
    "    neighbors_algorithm = \"auto\", #алгоритм, который ищет соседей. Инстанс класса NearestNeighbours\n",
    "    n_jobs = -1 #объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "UMAP_module = DimensionReducer(\n",
    "    gen_class = umap.UMAP,\n",
    "    n_neighbors = 5,  # количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2, # сколько оставить компонентов; по дефолту - 2\n",
    "    min_dist = 0.1    # минимальная дистанция, которую можно сохранять между точками в получающемся пространстве. \n",
    "    # Гиперпараметр. При увеличении начинает лучше улавливать общую структуру, но хуже - локальную\n",
    ")\n",
    "\n",
    "CombWRef_module = CombineWithReferenceFeature_adj(\n",
    "    operations = ['mul']\n",
    ")\n",
    "\n",
    "lgbm_mdl = LGBMClassifier(\n",
    "    num_leaves = 10,\n",
    "    learning_rate = .1,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda = 8,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# Tackling imbalances in target\n",
    "RUS_module    = RandomUnderSampler(random_state = seed)\n",
    "ROS_module    = RandomOverSampler(random_state = seed)\n",
    "SMOTE_module  = SMOTE(random_state = seed)\n",
    "ADASYN_module = ADASYN(random_state = seed)\n",
    "\n",
    "# feature selection\n",
    "SeqFearSel_module = SequentialFeatureSelector(\n",
    "    estimator  = lgbm_mdl,  \n",
    "    # k_features = 5,                                                  \n",
    "    forward    = True,                                                  \n",
    "    floating   = True,                                                \n",
    "    verbose    = 0,\n",
    "    cv         = 5\n",
    ")\n",
    "RecFeatAdd_module = RecursiveFeatureAddition(\n",
    "    lgbm_mdl,\n",
    "    threshold = 0.005\n",
    ")\n",
    "# SelShuffl_module = SelectByShuffling(\n",
    "#     estimator = lgbm_mdl,\n",
    "#     # variables=X.columns.to_list(),                                      # можно задать подмножество\n",
    "#     scoring='roc_auc',                                                  # метрика\n",
    "#     threshold=0.01,                                                     # порог ее снижения\n",
    "#     cv=5,\n",
    "#     random_state=42\n",
    "# )\n",
    "SmartSel_module = SmartCorrelatedSelection(\n",
    "    # variables=X.columns.to_list(),\n",
    "    method=\"pearson\",                # можно взять свою функцию\n",
    "    threshold=0.3,                   # порог корреляции\n",
    "    selection_method=\"variance\",     # из коррелирующих групп выбираем признак с наиб дисперсией\n",
    "    estimator=None,                  # понадобится для selection_method=\"model_performance\"        \n",
    "    cv=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12046c50-6419-41a5-add4-99f4329eda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'WoE':         WoE_module,\n",
    "    'OneHot':      OneHot_module,\n",
    "    'PCA':         PCA_module,\n",
    "    'kPCA':        kPCA_module,\n",
    "    'Isomap':      Isomap_module,\n",
    "    'UMAP':        UMAP_module,\n",
    "    'CombWRef':    CombWRef_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    'lgbm':        lgbm_mdl,\n",
    "    'RUS':         RUS_module,      \n",
    "    'ROS':         ROS_module,      \n",
    "    'SMOTE':       SMOTE_module,  \n",
    "    'ADASYN':      ADASYN_module,\n",
    "    'SeqFearSel':  SeqFearSel_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    # 'SelShuffl':   SelShuffl_module,\n",
    "    'SmartSel':    SmartSel_module    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9191776-4f78-43dc-aa59-162abcb164d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Define Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb5e9c-b033-4ce9-a5eb-113692201e73",
   "metadata": {},
   "source": [
    "Статья с примером [здесь](https://towardsdatascience.com/an-example-of-hyperparameter-optimization-on-xgboost-lightgbm-and-catboost-using-hyperopt-12bc41a271e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc113da-2803-4158-b23f-685890180303",
   "metadata": {},
   "source": [
    "### 4.1. Структура Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcacdc-9228-4db2-b546-25700f07e8e6",
   "metadata": {},
   "source": [
    "Определим структуру самого пайплайна. Словесное описание:\n",
    "    \n",
    "1. Энкодинг категориальных переменных:\n",
    "    + OneHotEncoder\n",
    "    + WoE\n",
    "3. Feature Engineering:\n",
    "    + PCA\n",
    "    + Kernel PCA\n",
    "    + Isomap\n",
    "    + UMAP\n",
    "    + Combine with Reference (feature multiplication)\n",
    "    + _отсутствует_\n",
    "4. Feature Selection:\n",
    "    + RecursiveFeatureAddition\n",
    "    + SequentialFeatureSelector\n",
    "    + SmartCorrelatedSelection\n",
    "    + _отсутствует_\n",
    "4. Resampling:\n",
    "    + Randomised Undersampling (RUS)\n",
    "    + Randomised Oversampling  (ROS)\n",
    "    + Synthetic Minority Oversampling Technique (SMOTE)\n",
    "    + Adaptive Synthetic (ADASYN)\n",
    "    + _отсутствует_\n",
    "5. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda1a09-9ad5-480d-b1ef-7ecdeaa21774",
   "metadata": {},
   "source": [
    "А так это будет выражаться в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af3a5d1-d094-4acd-a218-a6e3839928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    # 'missing_vals': \n",
    "    'cat_encoding':  hp.choice('cat_encoding', ['OneHot', 'WoE']), # , 'woe' пропустить нельзя из-за наличия кат. пер-х\n",
    "    'imbalance':     hp.choice('imbalance',    ['skip', 'RUS', 'ROS', 'SMOTE', 'ADASYN']),\n",
    "    'feat_eng':      hp.choice('feat_eng',     ['skip', 'PCA', 'kPCA', 'Isomap', 'UMAP']), # , 'CombWRef' # удалил, т.к. долго считается\n",
    "    # 'feat_filter':   hp.choice() -- unstable, low quality (SHAP, IV, feat_importance, ...) \n",
    "    'feat_sel':      hp.choice('feat_sel',     ['skip', 'SeqFearSel', 'RecFeatAdd', 'SmartSel']), # 'SelShuffl' is omitted, since it might drop all Xs\n",
    "    'lgbm':          'lgbm'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9529da0-a54b-46ee-b43b-b6f5a14b4705",
   "metadata": {},
   "source": [
    "Заметим, что 'skip' позволяет игнорировать соответствующий шаг в пайплайне. Названия типа `\"onehot\"` должны совпадать с названиями в словаре `modules`, который мы определили на Шаге 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e3b4f-8611-485d-9b80-fd347684a1e2",
   "metadata": {},
   "source": [
    "### 4.2. Гиперпараметры модулей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1b7ab-92ba-4154-9936-c218e70f8dbf",
   "metadata": {},
   "source": [
    "В следующий словарь добавляем гиперпараметры каждого из модулей, которые мы хотим оптимизировать. Названия строятся следующи образом:\n",
    "\n",
    "`<Название модуля>__<название параметра>`\n",
    "\n",
    "Например, чтобы задать параметр `num_leaves` модуля lgbm, трубуется добваить значение с ключем `lgbm__num_leaves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b710156-03b3-4e15-9b8f-3d1056037741",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_params = {\n",
    "    # OneHotEncoder does not need hyperparams\n",
    "    # RecFeatAdd might be redefined to receive a correct estimator\n",
    "    # PCA\n",
    "    'DimRed__PCA__n_components':      hp.choice('PCA__n_components',      np.arange(2, 11)),\n",
    "    'DimRed__PCA__whiten':            hp.choice('PCA__whiten',            [True, False]),\n",
    "    'DimRed__PCA__svd_solver':        hp.choice('PCA__svd_solver',        ['full', 'arpack', 'auto', 'randomized']),\n",
    "    \n",
    "    # kPCA\n",
    "    'DimRed__kPCA__n_components':     hp.choice('kPCA__n_components',     np.arange(5, 11)),\n",
    "    'DimRed__kPCA__kernel':           hp.choice('kPCA__kernel',           ['linear', 'poly', 'rbf', 'sigmoid', 'cosine', 'precomputed']),\n",
    "    \n",
    "    # Isomap\n",
    "    'DimRed__Isomap__n_neighbors':    hp.choice('Isomap__n_neighbors',    np.arange(2, 11)),\n",
    "    'DimRed__Isomap__n_components':   hp.choice('Isomap__n_components',   np.arange(2, 5)),\n",
    "    'DimRed__Isomap__path_method':    hp.choice('Isomap__path_method',    ['auto', 'FW', 'D']),\n",
    "    \n",
    "    # UMAP\n",
    "    'DimRed__UMAP__n_neighbors':      hp.choice('UMAP__n_neighbors',      np.arange(2, 11)),\n",
    "    'DimRed__UMAP__n_components':     hp.choice('UMAP__n_components',     np.arange(2, 11)),\n",
    "    'DimRed__UMAP__min_dist':         hp.choice('UMAP__min_dist',         np.arange(0.05, 1, 0.05)),\n",
    "    \n",
    "    # LightGBM\n",
    "    'lgbm__learning_rate':    hp.choice('lgbm__learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'lgbm__num_leaves':       hp.choice('lgbm__num_leaves',       np.arange(5, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_alpha':        hp.choice('lgbm__reg_alpha',        np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_lambda':       hp.choice('lgbm__reg_lambda',       np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__n_estimators':     100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e087a-0d3e-45ab-95a4-51dfa65d4fe0",
   "metadata": {},
   "source": [
    "Чтобы параметры можно было оптимизировать, модули должны иметь метод `.set_params()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0394d46-ceb8-4d7c-8d9f-34ae8a58c8a8",
   "metadata": {},
   "source": [
    "### 4.3. Подстановка оптимизационной задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d558b4-e575-4e78-9999-72581f265261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technicals — define minimization task\n",
    "pipe_para = dict()\n",
    "pipe_para['pipe_params']    = pipe_params\n",
    "pipe_para['set_params']     = set_params\n",
    "pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.roc_auc_score(y, pred)\n",
    "# pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.log_loss(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35572ab5-126d-4c78-a757-5a423def797f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 1000/1000 [1:38:46<00:00,  5.93s/trial, best loss: -0.781055342129054]\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "hpoptimizer = PipeHPOpt(X_train, y_train, modules=modules, mode='kfold', n_folds = 5, seed=seed)\n",
    "lgb_opt, trials = hpoptimizer.process(space=pipe_para, trials=Trials(), algo=tpe.suggest, max_evals=1000)\n",
    "\n",
    "# hpoptimizer = PipeStructHPOpt(X_train, y_train, modules, space_params=set_params, mode='kfold', n_folds = 5, seed=seed)\n",
    "# lgb_opt, trials = hpoptimizer.process(space_steps=steps, trials=Trials(), algo=tpe.suggest, max_evals=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4f5de-fb1e-4ecd-ae57-bbb5da1f1c76",
   "metadata": {},
   "source": [
    "### 4.4. Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739b7ca6-89f8-46a5-8b4c-78a33730fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_func': <function __main__.<lambda>(y, pred)>,\n",
       " 'pipe_params': {'cat_encoding': 'WoE',\n",
       "  'feat_eng': 'Isomap',\n",
       "  'feat_sel': 'skip',\n",
       "  'imbalance': 'ROS',\n",
       "  'lgbm': 'lgbm'},\n",
       " 'set_params': {'DimRed__Isomap__n_components': 3,\n",
       "  'DimRed__Isomap__n_neighbors': 2,\n",
       "  'DimRed__Isomap__path_method': 'D',\n",
       "  'DimRed__PCA__n_components': 7,\n",
       "  'DimRed__PCA__svd_solver': 'auto',\n",
       "  'DimRed__PCA__whiten': True,\n",
       "  'DimRed__UMAP__min_dist': 0.5,\n",
       "  'DimRed__UMAP__n_components': 3,\n",
       "  'DimRed__UMAP__n_neighbors': 8,\n",
       "  'DimRed__kPCA__kernel': 'rbf',\n",
       "  'DimRed__kPCA__n_components': 7,\n",
       "  'lgbm__learning_rate': 0.15000000000000002,\n",
       "  'lgbm__n_estimators': 100,\n",
       "  'lgbm__num_leaves': 5,\n",
       "  'lgbm__reg_alpha': 2,\n",
       "  'lgbm__reg_lambda': 5}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpoptimizer.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b71e6259-9a6b-48b3-be5e-afddd7b058a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\sklearn\\manifold\\_isomap.py:302: UserWarning: The number of connected components of the neighbors graph is 4 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "d:\\project\\credit_scoring_project\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1673: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('WoE',\n",
       "                 WoEEncoder_adj(variables=['cheq_acc', 'cred_hist', 'purp',\n",
       "                                           'save_acc', 'empl_t', 'pers_status',\n",
       "                                           'guarant_flg', 'prop', 'inst_plan',\n",
       "                                           'house', 'job', 'tel_flg',\n",
       "                                           'foreign_flg'])),\n",
       "                ('Isomap',\n",
       "                 <__main__.DimensionReducer object at 0x0000029DDF8FC220>),\n",
       "                ('ROS', RandomOverSampler(random_state=42)),\n",
       "                ('lgbm',\n",
       "                 LGBMClassifier(num_leaves=10, random_state=42, reg_alpha=8,\n",
       "                                reg_lambda=8))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mdl = hpoptimizer.get_best_model()\n",
    "best_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fc8832c-8df3-4acb-8535-11dc6a9523ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.7997758296899471\n",
      "Gini: 0.5766318067075369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5766318067075369"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gini(y_train, best_mdl.predict_proba(X_train)[:, 1])\n",
    "Gini(y_test, best_mdl.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b969a161-a175-454f-9b2b-83d2c74129a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.7763669646161422,\n",
       " -0.7228210631471275,\n",
       " -0.7279980280703995,\n",
       " -0.6765648599565901,\n",
       " -0.6822371267211811,\n",
       " -0.7113882733634889,\n",
       " -0.7469058170762046,\n",
       " -0.7611981268975534,\n",
       " -0.7606953878949908,\n",
       " -0.7619889593150948,\n",
       " -0.7763669646161422,\n",
       " -0.7190113457977975,\n",
       " -0.6863881490638676,\n",
       " -0.6066135856896097,\n",
       " -0.6822371267211811,\n",
       " -0.6173813969431191,\n",
       " -0.6075934839456696,\n",
       " -0.5628305070332584,\n",
       " -0.7432235356983659,\n",
       " -0.7279980280703995,\n",
       " -0.7697616993719443,\n",
       " -0.7763669646161422,\n",
       " -0.7763669646161422,\n",
       " -0.7763669646161422,\n",
       " -0.7659708443244196,\n",
       " -0.745541706328382,\n",
       " -0.7763669646161422,\n",
       " -0.7763669646161422,\n",
       " -0.7295152578895017,\n",
       " -0.7766649805243923,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7521694772278444,\n",
       " -0.7621907552843671,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.743174202500653,\n",
       " -0.7521694772278444,\n",
       " -0.7799523659322172,\n",
       " -0.7659708443244196,\n",
       " -0.7083253851737281,\n",
       " -0.7799523659322172,\n",
       " -0.7523034558312235,\n",
       " -0.7659215277197258,\n",
       " -0.7484745109835765,\n",
       " -0.7469623895666423,\n",
       " -0.6765648599565901,\n",
       " -0.7701427612972674,\n",
       " -0.771066279548377,\n",
       " -0.7070903925867305,\n",
       " -0.6876535804769295,\n",
       " -0.7634428220315704,\n",
       " -0.732867746190317,\n",
       " -0.7200775297644714,\n",
       " -0.5265903883135874,\n",
       " -0.7799523659322172,\n",
       " -0.7666255629287425,\n",
       " -0.7696225378491086,\n",
       " -0.6822371267211811,\n",
       " -0.7240079460192211,\n",
       " -0.7523923776559304,\n",
       " -0.7397868455239343,\n",
       " -0.7666255629287425,\n",
       " -0.7799523659322172,\n",
       " -0.6822371267211811,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7766649805243923,\n",
       " -0.7799523659322172,\n",
       " -0.7737321996773041,\n",
       " -0.7072429757585791,\n",
       " -0.7799523659322172,\n",
       " -0.7619889593150948,\n",
       " -0.7113882733634889,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.6822371267211811,\n",
       " -0.7521694772278444,\n",
       " -0.7537676949779093,\n",
       " -0.7439258457116631,\n",
       " -0.7737321996773041,\n",
       " -0.7685451990229816,\n",
       " -0.6075934839456696,\n",
       " -0.7521694772278444,\n",
       " -0.7736191065590333,\n",
       " -0.751620326458971,\n",
       " -0.7799523659322172,\n",
       " -0.7372492005692953,\n",
       " -0.7799523659322172,\n",
       " -0.6844897242343814,\n",
       " -0.7388861959644296,\n",
       " -0.7200775297644714,\n",
       " -0.7799523659322172,\n",
       " -0.7465562837587328,\n",
       " -0.7634226982376883,\n",
       " -0.7766649805243923,\n",
       " -0.6075934839456696,\n",
       " -0.7438520510048094,\n",
       " -0.7799523659322172,\n",
       " -0.7560588881377643,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7351066874207468,\n",
       " -0.6842152966189984,\n",
       " -0.7799523659322172,\n",
       " -0.7190113457977975,\n",
       " -0.7501775442350683,\n",
       " -0.7701427612972674,\n",
       " -0.7736191065590333,\n",
       " -0.7799523659322172,\n",
       " -0.5465401276337636,\n",
       " -0.7634226982376883,\n",
       " -0.7199467202884614,\n",
       " -0.7540648501501306,\n",
       " -0.7799523659322172,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.6125724502677589,\n",
       " -0.6942094321260884,\n",
       " -0.7619889593150948,\n",
       " -0.7621907552843671,\n",
       " -0.769298732439806,\n",
       " -0.7799523659322172,\n",
       " -0.7569918077813738,\n",
       " -0.6822371267211811,\n",
       " -0.7799523659322172,\n",
       " -0.6454992937243428,\n",
       " -0.720562575668731,\n",
       " -0.7799523659322172,\n",
       " -0.7691335429989757,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.6125724502677589,\n",
       " -0.7521694772278444,\n",
       " -0.7502197792921577,\n",
       " -0.7634226982376883,\n",
       " -0.7766649805243923,\n",
       " -0.7571777044430898,\n",
       " -0.6822371267211811,\n",
       " -0.7799523659322172,\n",
       " -0.7521694772278444,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7736191065590333,\n",
       " -0.7428552008997732,\n",
       " -0.7799523659322172,\n",
       " -0.7619889593150948,\n",
       " -0.7691335429989757,\n",
       " -0.6822371267211811,\n",
       " -0.7799523659322172,\n",
       " -0.7701427612972674,\n",
       " -0.7469623895666423,\n",
       " -0.7621907552843671,\n",
       " -0.7354486070906907,\n",
       " -0.7690406717594712,\n",
       " -0.7799523659322172,\n",
       " -0.6690115211431148,\n",
       " -0.7697616993719443,\n",
       " -0.7521694772278444,\n",
       " -0.7560588881377643,\n",
       " -0.7447402558159173,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7619889593150948,\n",
       " -0.6690115211431148,\n",
       " -0.7799523659322172,\n",
       " -0.7438520510048094,\n",
       " -0.7701427612972674,\n",
       " -0.7560588881377643,\n",
       " -0.7799523659322172,\n",
       " -0.7649817067628638,\n",
       " -0.7619889593150948,\n",
       " -0.6173813969431191,\n",
       " -0.7190113457977975,\n",
       " -0.7799523659322172,\n",
       " -0.7697616993719443,\n",
       " -0.7621907552843671,\n",
       " -0.7736191065590333,\n",
       " -0.7701427612972674,\n",
       " -0.5800138781482289,\n",
       " -0.7634226982376883,\n",
       " -0.7766649805243923,\n",
       " -0.7190113457977975,\n",
       " -0.7799523659322172,\n",
       " -0.7288673484692799,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.7736191065590333,\n",
       " -0.546245066900007,\n",
       " -0.7799523659322172,\n",
       " -0.7634226982376883,\n",
       " -0.7397868455239343,\n",
       " -0.7583943683074972,\n",
       " -0.7799523659322172,\n",
       " -0.7666255629287425,\n",
       " -0.7799523659322172,\n",
       " -0.7799523659322172,\n",
       " -0.6822371267211811,\n",
       " -0.6887326617448062,\n",
       " -0.7619889593150948,\n",
       " -0.7799523659322172,\n",
       " -0.7540648501501306,\n",
       " -0.7799523659322172,\n",
       " -0.7697616993719443,\n",
       " -0.6173813969431191,\n",
       " -0.7469623895666423,\n",
       " -0.7544183231041084,\n",
       " -0.7799523659322172,\n",
       " -0.7523923776559304,\n",
       " -0.7766649805243923,\n",
       " -0.7571777044430898,\n",
       " -0.7737321996773041,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7403732503363559,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.6822371267211811,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7403732503363559,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.763370824161146,\n",
       " -0.7686070174846559,\n",
       " -0.7666255629287425,\n",
       " -0.6876535804769295,\n",
       " -0.7697616993719443,\n",
       " -0.7528935532773386,\n",
       " -0.7659708443244196,\n",
       " -0.7412199775109352,\n",
       " -0.781055342129054,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7666255629287425,\n",
       " -0.7438520510048094,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.6765648599565901,\n",
       " -0.781055342129054,\n",
       " -0.7528935532773386,\n",
       " -0.7697616993719443,\n",
       " -0.7522353772725473,\n",
       " -0.781055342129054,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.6842152966189984,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.7438520510048094,\n",
       " -0.7686070174846559,\n",
       " -0.7570252560386876,\n",
       " -0.7601355469418041,\n",
       " -0.7766649805243923,\n",
       " -0.781055342129054,\n",
       " -0.6840118278372931,\n",
       " -0.781055342129054,\n",
       " -0.7208394224635677,\n",
       " -0.7666255629287425,\n",
       " -0.7697616993719443,\n",
       " -0.7531429370329049,\n",
       " -0.768244856366526,\n",
       " -0.7659708443244196,\n",
       " -0.7685451990229816,\n",
       " -0.7686070174846559,\n",
       " -0.6876535804769295,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7290948914221478,\n",
       " -0.7697616993719443,\n",
       " -0.768244856366526,\n",
       " -0.781055342129054,\n",
       " -0.7696225378491086,\n",
       " -0.7659708443244196,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7437953901700384,\n",
       " -0.7555706455988637,\n",
       " -0.781055342129054,\n",
       " -0.7569918077813738,\n",
       " -0.7583943683074972,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.6822371267211811,\n",
       " -0.781055342129054,\n",
       " -0.7528935532773386,\n",
       " -0.7484745109835765,\n",
       " -0.7766649805243923,\n",
       " -0.7478573150338058,\n",
       " -0.781055342129054,\n",
       " -0.769298732439806,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7626000840841876,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.7694387144148642,\n",
       " -0.7538823792617176,\n",
       " -0.7666255629287425,\n",
       " -0.7685451990229816,\n",
       " -0.7697616993719443,\n",
       " -0.6173813969431191,\n",
       " -0.781055342129054,\n",
       " -0.7403732503363559,\n",
       " -0.781055342129054,\n",
       " -0.7460574857077912,\n",
       " -0.751124101750982,\n",
       " -0.7690406717594712,\n",
       " -0.7691335429989757,\n",
       " -0.781055342129054,\n",
       " -0.6822371267211811,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7403732503363559,\n",
       " -0.7489878160743609,\n",
       " -0.7570252560386876,\n",
       " -0.7619889593150948,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.6765648599565901,\n",
       " -0.7697616993719443,\n",
       " -0.7208394224635677,\n",
       " -0.781055342129054,\n",
       " -0.7594907447954784,\n",
       " -0.7570252560386876,\n",
       " -0.7766649805243923,\n",
       " -0.7569407644695281,\n",
       " -0.781055342129054,\n",
       " -0.6173813969431191,\n",
       " -0.7666255629287425,\n",
       " -0.7697616993719443,\n",
       " -0.7528935532773386,\n",
       " -0.7501936688830977,\n",
       " -0.7522353772725473,\n",
       " -0.7766649805243923,\n",
       " -0.7696225378491086,\n",
       " -0.763370824161146,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7388861959644296,\n",
       " -0.7576619386883945,\n",
       " -0.7412199775109352,\n",
       " -0.7684459267146054,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.6842152966189984,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7233668550516189,\n",
       " -0.7714528548291893,\n",
       " -0.7570252560386876,\n",
       " -0.7766649805243923,\n",
       " -0.7659708443244196,\n",
       " -0.7685451990229816,\n",
       " -0.6876535804769295,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7437953901700384,\n",
       " -0.7702553823343805,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.769298732439806,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.7659708443244196,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7492398168572681,\n",
       " -0.6876535804769295,\n",
       " -0.7766649805243923,\n",
       " -0.7388861959644296,\n",
       " -0.769298732439806,\n",
       " -0.7412199775109352,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.781055342129054,\n",
       " -0.5937418497803019,\n",
       " -0.781055342129054,\n",
       " -0.7414831201794199,\n",
       " -0.7686070174846559,\n",
       " -0.7691335429989757,\n",
       " -0.7697616993719443,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.575758811389052,\n",
       " -0.7686070174846559,\n",
       " -0.7437953901700384,\n",
       " -0.7766649805243923,\n",
       " -0.7691335429989757,\n",
       " -0.7570252560386876,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7686070174846559,\n",
       " -0.5537216968524135,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.7437953901700384,\n",
       " -0.7685451990229816,\n",
       " -0.7570252560386876,\n",
       " -0.7666255629287425,\n",
       " -0.7686070174846559,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.5318638369743967,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.7451298194199492,\n",
       " -0.781055342129054,\n",
       " -0.7490400630577062,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7506932793779839,\n",
       " -0.7469058170762046,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7569407644695281,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.5355192523113388,\n",
       " -0.781055342129054,\n",
       " -0.7686070174846559,\n",
       " -0.7766649805243923,\n",
       " -0.7259115995648484,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7608380394257434,\n",
       " -0.7559499563276406,\n",
       " -0.6876535804769295,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.770472598019323,\n",
       " -0.7570252560386876,\n",
       " -0.7484745109835765,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.5901301097543062,\n",
       " -0.7697616993719443,\n",
       " -0.7766649805243923,\n",
       " -0.781055342129054,\n",
       " -0.732867746190317,\n",
       " -0.7218495314602458,\n",
       " -0.781055342129054,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.590749962693517,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7199467202884614,\n",
       " -0.7697616993719443,\n",
       " -0.7685451990229816,\n",
       " -0.7522353772725473,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.5457232548823672,\n",
       " -0.7686070174846559,\n",
       " -0.7666255629287425,\n",
       " -0.7532934716131846,\n",
       " -0.7697616993719443,\n",
       " -0.7685451990229816,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.5522493318796704,\n",
       " -0.763370824161146,\n",
       " -0.7471915015842916,\n",
       " -0.781055342129054,\n",
       " -0.769298732439806,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.7626000840841876,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7545259640630789,\n",
       " -0.781055342129054,\n",
       " -0.7190113457977975,\n",
       " -0.7766649805243923,\n",
       " -0.7686070174846559,\n",
       " -0.7697616993719443,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.781055342129054,\n",
       " -0.5818739755300683,\n",
       " -0.7619889593150948,\n",
       " -0.7208394224635677,\n",
       " -0.781055342129054,\n",
       " -0.7691335429989757,\n",
       " -0.7570252560386876,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.5850475166147631,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7414831201794199,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.7490400630577062,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7661383530557967,\n",
       " -0.781055342129054,\n",
       " -0.6822371267211811,\n",
       " -0.7414831201794199,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.7288673484692799,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7799523659322172,\n",
       " -0.5487876414652463,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7048404822189961,\n",
       " -0.7685451990229816,\n",
       " -0.7490400630577062,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.6876535804769295,\n",
       " -0.7612063964808278,\n",
       " -0.7686070174846559,\n",
       " -0.7532934716131846,\n",
       " -0.763370824161146,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.7570252560386876,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.7686070174846559,\n",
       " -0.6876535804769295,\n",
       " -0.7626007759391469,\n",
       " -0.7528935532773386,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.771066279548377,\n",
       " -0.7666255629287425,\n",
       " -0.7686070174846559,\n",
       " -0.7697616993719443,\n",
       " -0.6876535804769295,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7558793466586827,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.7208911914821086,\n",
       " -0.7685451990229816,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.6822371267211811,\n",
       " -0.781055342129054,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7571241493459228,\n",
       " -0.7208394224635677,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.751124101750982,\n",
       " -0.7685451990229816,\n",
       " -0.7666255629287425,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7701427612972674,\n",
       " -0.7528935532773386,\n",
       " -0.7574743484905446,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.7619889593150948,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.6075934839456696,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7521694772278444,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7636878620968648,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.7619889593150948,\n",
       " -0.7696225378491086,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.6876535804769295,\n",
       " -0.7438520510048094,\n",
       " -0.781055342129054,\n",
       " -0.7799523659322172,\n",
       " -0.7522353772725473,\n",
       " -0.781055342129054,\n",
       " -0.7479130762237731,\n",
       " -0.7690406717594712,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.6863881490638676,\n",
       " -0.7666255629287425,\n",
       " -0.7528935532773386,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.743174202500653,\n",
       " -0.7702425226169796,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.6842152966189984,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.7388861959644296,\n",
       " -0.7686070174846559,\n",
       " -0.7697616993719443,\n",
       " -0.7621907552843671,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.760810708492677,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7619889593150948,\n",
       " -0.7696225378491086,\n",
       " -0.7528935532773386,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.7602959705578577,\n",
       " -0.6173813969431191,\n",
       " -0.7619889593150948,\n",
       " -0.732867746190317,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.7697616993719443,\n",
       " -0.7686070174846559,\n",
       " -0.7799523659322172,\n",
       " -0.7577144364312045,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.732867746190317,\n",
       " -0.7666255629287425,\n",
       " -0.7412199775109352,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7673032959500354,\n",
       " -0.7532934716131846,\n",
       " -0.7484745109835765,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.7490400630577062,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7581752413529795,\n",
       " -0.7208394224635677,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.771066279548377,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7737321996773041,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6488085674214551,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.7437953901700384,\n",
       " -0.7685451990229816,\n",
       " -0.7666255629287425,\n",
       " -0.7570252560386876,\n",
       " -0.7686070174846559,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7799523659322172,\n",
       " -0.6822371267211811,\n",
       " -0.7691369598837834,\n",
       " -0.7528935532773386,\n",
       " -0.7619889593150948,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.7412199775109352,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7659708443244196,\n",
       " -0.7087527458575968,\n",
       " -0.7686070174846559,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.771066279548377,\n",
       " -0.781055342129054,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.6876535804769295,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7171159167256993,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.781055342129054,\n",
       " -0.7540648501501306,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6153281599455374,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.761497852416373,\n",
       " -0.768244856366526,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.7569918077813738,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.6822371267211811,\n",
       " -0.7521694772278444,\n",
       " -0.7659708443244196,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7492831672768803,\n",
       " -0.7537676949779093,\n",
       " -0.763370824161146,\n",
       " -0.7685451990229816,\n",
       " -0.781055342129054,\n",
       " -0.6765648599565901,\n",
       " -0.7697616993719443,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7521694772278444,\n",
       " -0.781055342129054,\n",
       " -0.7562477040713389,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.7691335429989757,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7528935532773386,\n",
       " -0.7697616993719443,\n",
       " -0.7701427612972674,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.758878777285431,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7685451990229816,\n",
       " -0.7068466827468027,\n",
       " -0.6876535804769295,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7522353772725473,\n",
       " -0.7464015668828201,\n",
       " -0.781055342129054,\n",
       " -0.7766649805243923,\n",
       " -0.6066135856896097,\n",
       " -0.781055342129054,\n",
       " -0.7691335429989757,\n",
       " -0.7438520510048094,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7621907552843671,\n",
       " -0.7541351945318302,\n",
       " -0.7686070174846559,\n",
       " -0.7766649805243923,\n",
       " -0.781055342129054,\n",
       " -0.6876535804769295,\n",
       " -0.7569407644695281,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7501775442350683,\n",
       " -0.7617062656940979,\n",
       " -0.781055342129054,\n",
       " -0.7508791622605063,\n",
       " -0.781055342129054,\n",
       " -0.6842152966189984,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7190113457977975,\n",
       " -0.781055342129054,\n",
       " -0.7686070174846559,\n",
       " -0.781055342129054,\n",
       " -0.7501775442350683,\n",
       " -0.781055342129054,\n",
       " -0.7486212441260697,\n",
       " -0.7736191065590333,\n",
       " -0.6876535804769295,\n",
       " -0.7766649805243923,\n",
       " -0.781055342129054,\n",
       " -0.7437953901700384,\n",
       " -0.7696225378491086,\n",
       " -0.7666255629287425,\n",
       " -0.781055342129054,\n",
       " -0.7570252560386876,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.781055342129054,\n",
       " -0.7659708443244196,\n",
       " -0.6876535804769295,\n",
       " -0.7376455540896039,\n",
       " -0.7528935532773386,\n",
       " -0.781055342129054,\n",
       " -0.763370824161146,\n",
       " -0.781055342129054,\n",
       " -0.7540648501501306,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7697616993719443,\n",
       " -0.7799523659322172,\n",
       " -0.6173813969431191,\n",
       " -0.762362495420607,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.781055342129054,\n",
       " -0.7532934716131846,\n",
       " -0.7569407644695281,\n",
       " -0.781055342129054]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['loss'] for r in trials.results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e1fb6ef-47c1-430b-b686-afe89e47b1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array([r['loss'] for r in trials.results]))\n",
    "plt.title('Hyperopt: loss function dynamics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average loss (-AUC) on k cross-validation samples')\n",
    "plt.show()\n",
    "plt.savefig('loss_dynamics_hp_1000_tpe_suggest.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
