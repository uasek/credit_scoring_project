{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b95fcbe-4085-4cb6-8fde-7c4601826387",
   "metadata": {
    "id": "mlhq3qfjqFO2"
   },
   "source": [
    "# Model Risk Pipeline\n",
    "\n",
    "_Initial commit: Anton Markov, 19 November 2021_\n",
    "\n",
    "Основная цель данного ноутбука — построить базовую структуру пайплайна с учетом оптимизации гиперпараметров.\n",
    "\n",
    "Реализована оптимизация через `hyperopt`, в будущем возможно поддержка иных библиотек.\n",
    "\n",
    "__Входные данные:__\n",
    "\n",
    "1. Датасет\n",
    "2. Модель\n",
    "3. Список модулей, которые могут оптимизироваться в качества гиперпараметра\n",
    "\n",
    "__Исходящие данные:__\n",
    "\n",
    "1. Оптимальный набор модулей, согласно `hyperopt`\n",
    "2. Параметры обученной оптимальной модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9abbb-ee51-484f-96b8-192c3474e7ff",
   "metadata": {},
   "source": [
    "## 1. Technicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b144269a-e212-4862-bccc-765c1e35f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hyperopt import hp\n",
    "# from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# for HyperOpt class\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb6db62-76e3-41f8-9f1d-5058cadc1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# новый пакет!\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from feature_engine.selection import RecursiveFeatureAddition\n",
    "from feature_engine.encoding import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0184b01-7b88-4340-a73c-73677be9af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30298cd5-9826-403f-b63e-e6cab89a064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/01_german/factors.json') as json_file:\n",
    "    factors_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd10c8d-7b07-424f-a198-8eef180911e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheq_acc',\n",
       " 'cred_hist',\n",
       " 'purp',\n",
       " 'save_acc',\n",
       " 'empl_t',\n",
       " 'pers_status',\n",
       " 'guarant_flg',\n",
       " 'prop',\n",
       " 'inst_plan',\n",
       " 'house',\n",
       " 'job',\n",
       " 'tel_flg',\n",
       " 'foreign_flg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_dict['cat_vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2550a6d-604b-4c7c-9929-0d9365b10eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ac53db-2b8f-45b7-b253-509fa7045915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y, y_pred):\n",
    "    res = roc_auc_score(y, y_pred) * 2 - 1\n",
    "    print(f\"Gini: {res}\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020c325-11af-4cfc-9d61-5d2378598fdd",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b36c16-1aa8-41a0-8462-74cfbe7fc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../datasets/01_german/samples/X_train.parquet')\n",
    "y_train = pd.read_parquet('../datasets/01_german/samples/y_train.parquet').target\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test  = pd.read_parquet('../datasets/01_german/samples/X_test.parquet')\n",
    "y_test  = pd.read_parquet('../datasets/01_german/samples/y_test.parquet').target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58540fea-e6ce-462c-8427-30f443126065",
   "metadata": {},
   "source": [
    "### Модули"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773fea9-9067-4d91-a30d-4594eb5a3716",
   "metadata": {},
   "source": [
    "Для примера использую облегченную версию пайплайна:\n",
    "    \n",
    "0. Входные данные для обучения - обучающая и валидационная выборки,\n",
    "1. Энкодинг категориальных переменных:\n",
    "    + OneHotEncoder\n",
    "    + WOE\n",
    "3. Feature Engineering:\n",
    "    + PCA\n",
    "    + Kernel PCA\n",
    "    + CombineWithReferenceFeature\n",
    "    + _отсутствует_\n",
    "4. Feature Selection:\n",
    "    + RecursiveFeatureAddition\n",
    "    + _отсутствует_\n",
    "5. LightGBM\n",
    "\n",
    "\n",
    "Все параметры модулей оптимизируются. Кроме того, оптимизируется сам набор модулей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3c5e57-7b87-420b-b5a8-8bcedade03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineWithReferenceFeature_adj():\n",
    "    '''\n",
    "    Обертка вокруг CombineWithReferenceFeature()\n",
    "    Позволяет не устанавливать параметры\n",
    "    + variables_to_combine\n",
    "    + reference_variables\n",
    "    заранее (иначе не будет работать с OneHotEncoder\n",
    "    и прочими преобразователями данных, а делать это при .fit()\n",
    "    '''\n",
    "    def __init__(self, operations):\n",
    "        self.operations = operations\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.combinator = CombineWithReferenceFeature(\n",
    "            variables_to_combine = list(X.columns),\n",
    "            reference_variables = list(X.columns),\n",
    "            operations = self.operations\n",
    "        )\n",
    "        self.combinator.fit(X, y)\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return(self.combinator.transform(X))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b6161f-6a9c-456b-8d1f-d512d792c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPCA_adj():\n",
    "    '''\n",
    "    Обертка нужна, чтобы transform() возвращал\n",
    "    pd.df(), а не np.array() - не все могут в np\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pca = sklearn.decomposition.KernelPCA(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.pca.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.DataFrame(self.pca.transform(X), index = X.index)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.pca.set_params(**kwargs)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0293bc-daf0-4920-b7ae-4d28283a0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22dc81ed-dce6-4a74-a8cd-549a82b69ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe = WoEEncoder(variables = factors_dict['cat_vals'])\n",
    "onehot = OneHotEncoder(variables = factors_dict['cat_vals'])\n",
    "\n",
    "kPCA = KernelPCA_adj(\n",
    "    n_components = 8,  # сколько оставить компонентов; по дефолту - все\n",
    "    kernel = \"linear\", # ядро. По дфеолту линейное. Можно сделать своё, но тогда его нужно предварительно вычислить отдельно,\n",
    "                       # поставить kernel = \"precomputed\" и передать уже вычисленное ядро в качестве X\n",
    "    degree = 3,        # степень полинома для некоторых типов ядер. Важный параметр для тьюнинга, но сильно напрягает процессор\n",
    "    n_jobs = -1        # объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "feat_eng = CombineWithReferenceFeature_adj(\n",
    "    operations = ['mul']\n",
    ")\n",
    "\n",
    "lgbm_mdl = LGBMClassifier(\n",
    "    num_leaves = 10,\n",
    "    learning_rate = .1,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda = 8,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "feat_sel = RecursiveFeatureAddition(\n",
    "    lgbm_mdl,\n",
    "    threshold = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f5a1b-9029-4a41-8965-de25f6c2dfca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Проверка работы Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "262543ff-7197-453a-a200-6586c9061c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_pipe = Pipeline([\n",
    "    # ('woe', woe),\n",
    "    ('onehot', onehot), # must-have\n",
    "    ('kPCA', kPCA),\n",
    "    # ('UMAPer', UMAPer),\n",
    "    ('feat_eng', feat_eng),\n",
    "    # ('feat_select', feat_sel),\n",
    "    ('lgbm', lgbm_mdl) # must-have\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9366fe9-6ee2-4397-84ed-29fd22cfd4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.8604799619949672\n",
      "Gini: 0.6304844332251474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6304844332251474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_pipe.fit(X_train, y_train)\n",
    "Gini(y_train, mdl_pipe.predict_proba(X_train)[:, 1])\n",
    "Gini(y_test, mdl_pipe.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9191776-4f78-43dc-aa59-162abcb164d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Оптимизация параметров в конкретном пайплайне"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb5e9c-b033-4ce9-a5eb-113692201e73",
   "metadata": {},
   "source": [
    "Хорошая статья с примером [здесь](https://towardsdatascience.com/an-example-of-hyperparameter-optimization-on-xgboost-lightgbm-and-catboost-using-hyperopt-12bc41a271e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcacdc-9228-4db2-b546-25700f07e8e6",
   "metadata": {},
   "source": [
    "Ещё раз приведём все модули, которые используются для примера:\n",
    "    \n",
    "0. Входные данные для обучения - обучающая и валидационная выборки,\n",
    "1. Энкодинг категориальных переменных:\n",
    "    + OneHotEncoder\n",
    "    + WOE\n",
    "3. Feature Engineering:\n",
    "    + PCA\n",
    "    + Kernel PCA\n",
    "    + CombineWithReferenceFeature\n",
    "    + _отсутствует_\n",
    "4. Feature Selection:\n",
    "    + RecursiveFeatureAddition\n",
    "    + _отсутствует_\n",
    "5. LightGBM\n",
    "\n",
    "Все параметры модулей оптимизируются. Кроме того, оптимизируется сам набор модулей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f67310-3f9f-48a9-9335-693a3837a515",
   "metadata": {},
   "source": [
    "Now let's put `hyperopt` on top of that:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25468364-5ccb-434d-be1e-aa1aaf75ed8a",
   "metadata": {},
   "source": [
    "Optimizer definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "858e8dc9-f764-4f9c-965a-d6846f0c0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_params = {\n",
    "    'kPCA__n_components':     hp.choice('kPCA__n_components',     np.arange(5, 11)),\n",
    "    'lgbm__learning_rate':    hp.choice('lgbm__learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'lgbm__num_leaves':       hp.choice('lgbm__num_leaves',       np.arange(5, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_alpha':        hp.choice('lgbm__reg_alpha',        np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_lambda':       hp.choice('lgbm__reg_lambda',       np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__n_estimators':     100,\n",
    "}\n",
    "\n",
    "pipe_para = dict()\n",
    "pipe_para['set_params']     = set_params\n",
    "pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.roc_auc_score(y, pred)\n",
    "# pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.log_loss(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78c4043-556f-4975-9b14-d0333c507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class PipeHPOpt(object):\n",
    "\n",
    "    def __init__(self, X, y, reg, mode='kfold', n_folds = 5, test_size=.33, seed=42):\n",
    "        \n",
    "        if (mode != 'kfold') & (mode != 'valid'):\n",
    "            raise ValueError(\"Choose mode 'kfold' or 'valid'\")\n",
    "        if (mode == 'valid') & (n_folds != 5):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default n_folds won't be used since mode == valid!\")\n",
    "        if (mode == 'kfold') & (test_size != .33):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default test_size won't be used since mode == kfold!\")\n",
    "            \n",
    "        self.X       = X\n",
    "        self.y       = y\n",
    "        self.mode    = mode\n",
    "        self.n_folds = n_folds\n",
    "        self.seed    = seed\n",
    "        self.reg     = reg \n",
    "        \n",
    "        if mode == 'valid':\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "    def process(self, space, trials, algo, max_evals, fn_name='pipe'):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def pipe(self, para):\n",
    "        reg = self.reg\n",
    "        reg.set_params(**para['set_params'])\n",
    "        if self.mode == 'kfold':\n",
    "            return self.train_reg_kfold(reg, para)\n",
    "        elif self.mode == 'valid':\n",
    "            return self.train_reg_valid(reg, para)\n",
    "\n",
    "    def train_reg_valid(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        pred = reg.predict_proba(self.x_test)[:, 1]\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'model': reg, 'params': para['set_params'], 'status': STATUS_OK}\n",
    "    \n",
    "    def train_reg_kfold(self, reg, para):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.seed)\n",
    "        losses = []\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_split_train, X_split_test = self.X.iloc[train_index, :], self.X.iloc[test_index, :]\n",
    "            y_split_train, y_split_test = self.y.iloc[train_index, ],  self.y.iloc[test_index, ]\n",
    "            reg.fit(X_split_train, y_split_train)\n",
    "            pred = reg.predict_proba(X_split_test)[:, 1]\n",
    "            loss = para['loss_func'](y_split_test, pred)\n",
    "            losses.append(loss)\n",
    "        return {'loss': np.mean(losses), 'params': para['set_params'], 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3aa0f4e-0e4d-4982-8ff4-92e181951e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'woe':         woe,\n",
    "    'onehot':      onehot,\n",
    "    'kPCA':        kPCA,\n",
    "    'feat_eng':    feat_eng,\n",
    "    'feat_sel':    feat_sel,\n",
    "    'lgbm':        lgbm_mdl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e494634-ec67-4d9f-ac3c-5b6befd6402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Pipeline([\n",
    "    # ('woe',       self.mudules['woe']),\n",
    "    ('onehot',      modules['onehot']), # must-have\n",
    "    ('kPCA',        modules['kPCA']),\n",
    "    # ('UMAPer',    self.mudules['UMAPer']),\n",
    "    ('feat_eng',    modules['feat_eng']),\n",
    "    # ('feat_select', self.mudules['feat_sel']),\n",
    "    ('lgbm',        modules['lgbm']) # must-have\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c6bf604-d73c-4bbc-b7ec-ba43eaeba2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.32s/trial, best loss: -0.7383439048960536]\n"
     ]
    }
   ],
   "source": [
    "hpoptimizer = PipeHPOpt(X_train, y_train, reg=reg, mode='kfold', n_folds = 5, seed=seed)\n",
    "lgb_opt, trials = hpoptimizer.process(space=pipe_para, trials=Trials(), algo=tpe.suggest, max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56f654c1-0ac6-46bc-b766-8b98c91db0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model нельзя вытащить при обучении k_fold, требуется только переобучение с данными гиперпараметрами\n",
    "best_params = trials.results[np.argmin([r['loss'] for r in \n",
    "    trials.results])]['params']\n",
    "worst_params = trials.results[np.argmax([r['loss'] for r in \n",
    "    trials.results])]['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b85766-f090-4bdb-96bb-3d36f31b8fc8",
   "metadata": {},
   "source": [
    "## 3. Оптимизация структуры пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5c8c4-1721-4bb5-b3da-4d556ca97e5c",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0a8000b-7027-4583-9104-f60d68c1b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_params(params, pipe):\n",
    "    '''\n",
    "    From all input parameters filter only\n",
    "    those that are relevant for the current\n",
    "    pipeline\n",
    "    '''\n",
    "    pipe_steps = list(pipe.named_steps.keys())\n",
    "    params_keys = list(params.keys())\n",
    "    \n",
    "    return {\n",
    "        key: params[key]\n",
    "        for key in params_keys\n",
    "        if key.split('__')[0] in pipe_steps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e14158ad-c0f9-44fa-b5cc-e2ea6b92d5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## test\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     # ('woe',       self.mudules['woe']),\n",
    "#     ('onehot',      modules['onehot']), # must-have\n",
    "#     ('kPCA',        modules['kPCA']),\n",
    "#     # ('UMAPer',    self.mudules['UMAPer']),\n",
    "#     ('feat_eng',    modules['feat_eng']),\n",
    "#     # ('feat_select', self.mudules['feat_sel']),\n",
    "#     # ('lgbm',        modules['lgbm']) # must-have\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#     'kPCA__n_components':     8,\n",
    "#     'lgbm__learning_rate':    .1,\n",
    "#     'lgbm__num_leaves':       10,\n",
    "#     'lgbm__reg_alpha':        8,\n",
    "#     'lgbm__reg_lambda':       8,\n",
    "#     'lgbm__n_estimators':     100\n",
    "# }\n",
    "\n",
    "# filter_params(params, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b07cbc21-1fd1-4c24-b99a-e9e962fe825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pipe(steps_dict, modules):\n",
    "    '''\n",
    "    Construct a pipeline given structure\n",
    "    '''\n",
    "    return [(steps_dict[s], modules[steps_dict[s]]) for s in steps_dict if steps_dict[s] != 'skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12aa3070-8373-404b-bddf-20447f29a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "# construct_pipe({'cat_encoding': 'onehot', 'feat_eng': 'kPCA'}, modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767eb40d-a614-4240-acf5-bcf3567f3382",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b78b1-d039-42dd-b973-9fba0e583eba",
   "metadata": {},
   "source": [
    "При добавлении модуля нужно включить его в словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12046c50-6419-41a5-add4-99f4329eda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'woe':         woe,\n",
    "    'onehot':      onehot,\n",
    "    'kPCA':        kPCA,\n",
    "    'feat_eng':    feat_eng,\n",
    "    'feat_sel':    feat_sel,\n",
    "    'lgbm':        lgbm_mdl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda1a09-9ad5-480d-b1ef-7ecdeaa21774",
   "metadata": {},
   "source": [
    "Сюда добавляем описание того, как новый модуль будет использоваться в структуре пайплайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3af3a5d1-d094-4acd-a218-a6e3839928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cat_encoding':           hp.choice('cat_encoding', ['onehot']), # , 'woe' пропустить нельзя из-за наличия кат. пер-х\n",
    "    'feat_eng':               hp.choice('feat_eng',     ['skip', 'kPCA']),\n",
    "    'feat_sel':               hp.choice('feat_sel',     ['skip', 'feat_sel']),\n",
    "    'lgbm':                   'lgbm'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1b7ab-92ba-4154-9936-c218e70f8dbf",
   "metadata": {},
   "source": [
    "Сюда добавляем гиерпараметры новго модуля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b710156-03b3-4e15-9b8f-3d1056037741",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_params = {\n",
    "    'kPCA__n_components':     hp.choice('kPCA__n_components',     np.arange(5, 11)),\n",
    "    'lgbm__learning_rate':    hp.choice('lgbm__learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'lgbm__num_leaves':       hp.choice('lgbm__num_leaves',       np.arange(5, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_alpha':        hp.choice('lgbm__reg_alpha',        np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__reg_lambda':       hp.choice('lgbm__reg_lambda',       np.arange(0, 16, 1, dtype=int)),\n",
    "    'lgbm__n_estimators':     100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d558b4-e575-4e78-9999-72581f265261",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_para = dict()\n",
    "pipe_para['pipe_params']    = pipe_params\n",
    "pipe_para['set_params']     = set_params\n",
    "pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.roc_auc_score(y, pred)\n",
    "# pipe_para['loss_func']      = lambda y, pred: -sklearn.metrics.log_loss(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50161d88-bd50-4064-ab97-c932c00d1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class PipeHPOpt(object):\n",
    "\n",
    "    def __init__(self, X, y, modules, mode='kfold', n_folds = 5, test_size=.33, seed=42):\n",
    "        \n",
    "        if (mode != 'kfold') & (mode != 'valid'):\n",
    "            raise ValueError(\"Choose mode 'kfold' or 'valid'\")\n",
    "        if (mode == 'valid') & (n_folds != 5):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default n_folds won't be used since mode == valid!\")\n",
    "        if (mode == 'kfold') & (test_size != .33):\n",
    "            import warnings\n",
    "            warnings.warn(\"Non-default test_size won't be used since mode == kfold!\")\n",
    "            \n",
    "        self.X       = X\n",
    "        self.y       = y\n",
    "        self.mode    = mode\n",
    "        self.n_folds = n_folds\n",
    "        self.seed    = seed\n",
    "        self.reg     = reg \n",
    "        self.modules = modules\n",
    "        \n",
    "        if mode == 'valid':\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "    def process(self, space, trials, algo, max_evals, fn_name='pipe'):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def pipe(self, para):\n",
    "        # print(para)\n",
    "        pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "        reg = Pipeline(pipe_steps)\n",
    "        for p in pipe_para['set_params']:\n",
    "            try:\n",
    "                reg.set_params({p: para[p]})\n",
    "            except:\n",
    "                pass\n",
    "        if self.mode == 'kfold':\n",
    "            return self.train_reg_kfold(reg, para)\n",
    "        elif self.mode == 'valid':\n",
    "            return self.train_reg_valid(reg, para)\n",
    "\n",
    "    def train_reg_valid(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        pred = reg.predict_proba(self.x_test)[:, 1]\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'model': reg, 'params': para, 'status': STATUS_OK}\n",
    "    \n",
    "    def train_reg_kfold(self, reg, para):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.seed)\n",
    "        losses = []\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_split_train, X_split_test = self.X.iloc[train_index, :], self.X.iloc[test_index, :]\n",
    "            y_split_train, y_split_test = self.y.iloc[train_index, ],  self.y.iloc[test_index, ]\n",
    "            reg.fit(X_split_train, y_split_train)\n",
    "            pred = reg.predict_proba(X_split_test)[:, 1]\n",
    "            loss = para['loss_func'](y_split_test, pred)\n",
    "            losses.append(loss)\n",
    "        return {'loss': np.mean(losses), 'params': para, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35572ab5-126d-4c78-a757-5a423def797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [1:26:10<00:00,  5.17s/trial, best loss: -0.7731525296887065]\n"
     ]
    }
   ],
   "source": [
    "hpoptimizer = PipeHPOpt(X_train, y_train, modules=modules, mode='kfold', n_folds = 5, seed=seed)\n",
    "lgb_opt, trials = hpoptimizer.process(space=pipe_para, trials=Trials(), algo=tpe.suggest, max_evals=1000)\n",
    "\n",
    "# hpoptimizer = PipeStructHPOpt(X_train, y_train, modules, space_params=set_params, mode='kfold', n_folds = 5, seed=seed)\n",
    "# lgb_opt, trials = hpoptimizer.process(space_steps=steps, trials=Trials(), algo=tpe.suggest, max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a49dc714-1bc6-4cf3-b3c8-5b1cb5d3d4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_encoding': 0,\n",
       " 'feat_eng': 0,\n",
       " 'feat_sel': 0,\n",
       " 'kPCA__n_components': 1,\n",
       " 'lgbm__learning_rate': 4,\n",
       " 'lgbm__num_leaves': 4,\n",
       " 'lgbm__reg_alpha': 14,\n",
       " 'lgbm__reg_lambda': 12}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "739b7ca6-89f8-46a5-8b4c-78a33730fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_func': <function __main__.<lambda>(y, pred)>,\n",
       " 'pipe_params': {'cat_encoding': 'onehot',\n",
       "  'feat_eng': 'skip',\n",
       "  'feat_sel': 'skip',\n",
       "  'lgbm': 'lgbm'},\n",
       " 'set_params': {'kPCA__n_components': 6,\n",
       "  'lgbm__learning_rate': 0.25,\n",
       "  'lgbm__n_estimators': 100,\n",
       "  'lgbm__num_leaves': 9,\n",
       "  'lgbm__reg_alpha': 14,\n",
       "  'lgbm__reg_lambda': 12}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a4a11-f1a4-4258-9ec1-bde0fb41df33",
   "metadata": {},
   "source": [
    "# Archive code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b4a5f96-cfda-40e0-9953-52baa8503f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para = {\n",
    "#     'loss_func': lambda y, pred: -sklearn.metrics.roc_auc_score(y, pred), \n",
    "#     'pipe_params': {'cat_encoding': 'onehot', 'feat_eng': 'skip'}, \n",
    "#     'set_params': {\n",
    "#         'kPCA__n_components': 10, \n",
    "#         'lgbm__learning_rate': 0.2, \n",
    "#         'lgbm__n_estimators': 100, \n",
    "#         'lgbm__num_leaves': 9, \n",
    "#         'lgbm__reg_alpha': 4, \n",
    "#         'lgbm__reg_lambda': 3\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ba5bcad-8b89-4e94-858b-5763c2b174f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in para['pipe_params']:\n",
    "#     if i != 'skip':\n",
    "#         print(para['pipe_params'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f35be931-7982-4a4c-8eef-8f95a684d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(para)\n",
    "# pipe_steps = [(para['pipe_params'][i], modules[para['pipe_params'][i]]) for i in para['pipe_params'] if para['pipe_params'][i] != 'skip']\n",
    "# reg = Pipeline(pipe_steps)\n",
    "# for p in pipe_para['set_params']:\n",
    "#     try:\n",
    "#         reg.set_params({p: para[p]})\n",
    "#     except:\n",
    "#         pass\n",
    "# if self.mode == 'kfold':\n",
    "#     return self.train_reg_kfold(reg, para)\n",
    "# elif self.mode == 'valid':\n",
    "#     return self.train_reg_valid(reg, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67a54eb4-23d0-41f0-afd1-1fa922f9280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import lightgbm as lgb\n",
    "# # import xgboost as xgb\n",
    "# # import catboost as ctb\n",
    "# from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class PipeStructHPOpt(object):\n",
    "\n",
    "#     def __init__(self, X, y, modules, space_params, mode='kfold', n_folds = 5, test_size=.33, seed=42):\n",
    "            \n",
    "#         self.X            = X\n",
    "#         self.y            = y\n",
    "#         self.mode         = mode\n",
    "#         self.n_folds      = n_folds\n",
    "#         self.seed         = seed\n",
    "#         self.reg          = reg \n",
    "#         self.modules      = modules\n",
    "#         self.space_params = space_params\n",
    "        \n",
    "#     def process(self, space_steps, trials, algo, max_evals):\n",
    "#         # fn = getattr(self, fn_name)    \n",
    "#         try:\n",
    "#             result = fmin(fn=self._struct_optimizer, space=space_steps, algo=algo, max_evals=max_evals, trials=trials)\n",
    "#         except Exception as e:\n",
    "#             return {'status': STATUS_FAIL,\n",
    "#                     'exception': str(e)}\n",
    "#         return result, trials\n",
    "\n",
    "#     def _struct_optimizer(self, para):        \n",
    "#         reg = Pipeline(construct_pipe(para, self.modules))      \n",
    "#         space_filtered = filter_params(self.space_params, reg)\n",
    "        \n",
    "#         hpoptimizer = PipeHPOpt(\n",
    "#             X       = self.X, \n",
    "#             y       = self.y, \n",
    "#             reg     = reg, \n",
    "#             mode    = self.mode, \n",
    "#             n_folds = self.n_folds, \n",
    "#             seed    = self.seed\n",
    "#         )\n",
    "#         lgb_opt, trials = hpoptimizer.process(space=space_filtered, trials=Trials(), algo=tpe.suggest, max_evals=10)\n",
    "#         return {\n",
    "#             'loss': np.min([r['loss'] for r in trials.results]), \n",
    "#             'params': para['set_params'], \n",
    "#             'status': STATUS_OK\n",
    "#         } "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
