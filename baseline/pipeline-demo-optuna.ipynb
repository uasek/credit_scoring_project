{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b95fcbe-4085-4cb6-8fde-7c4601826387",
   "metadata": {
    "id": "mlhq3qfjqFO2"
   },
   "source": [
    "# Optuna pipeline\n",
    "\n",
    "Цель данного ноутбука -- показать, как можно применять библиотеку `optuna` для оптимизации гиперпараметров и подбора элементов пайплайна. Начало скопировано из ноутбука про `hyperopt`.\n",
    "\n",
    "Главная [страница](https://optuna.org/) библиотеки. [Документация](https://optuna.readthedocs.io/en/stable/index.html).\n",
    "Судя по документации, это довольно интересная штука с большими возможностями по настройке, сохранению и обработке результатов экспериментов.\n",
    "Интересные страницы, которые стоит посмотреть:\n",
    " - [optuna.study](https://optuna.readthedocs.io/en/stable/reference/study.html)\n",
    " - [Study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study)\n",
    " - [Trial](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial)\n",
    " - [как настроить verbose](https://optuna.readthedocs.io/en/stable/reference/logging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a06e4",
   "metadata": {},
   "source": [
    "Далее идет кусок из ноута по `hyperopt`. Сделаю его позднее более коротким, но пока есть что есть :)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9abbb-ee51-484f-96b8-192c3474e7ff",
   "metadata": {},
   "source": [
    "## 1. Technicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b144269a-e212-4862-bccc-765c1e35f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import umap\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from hyperopt import hp\n",
    "# from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as ctb\n",
    "\n",
    "# новый пакет!\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "from typing import List, Union\n",
    "from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "from feature_engine.validation import _return_tags\n",
    "from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from feature_engine.selection  import SelectByShuffling\n",
    "from feature_engine.selection  import RecursiveFeatureAddition\n",
    "from feature_engine.selection  import SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ac53db-2b8f-45b7-b253-509fa7045915",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def Gini(y, y_pred):\n",
    "    res = roc_auc_score(y, y_pred) * 2 - 1\n",
    "    print(f\"Gini: {res}\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020c325-11af-4cfc-9d61-5d2378598fdd",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b36c16-1aa8-41a0-8462-74cfbe7fc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../datasets/01_german/samples/X_train.parquet')\n",
    "y_train = pd.read_parquet('../datasets/01_german/samples/y_train.parquet').target\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test  = pd.read_parquet('../datasets/01_german/samples/X_test.parquet')\n",
    "y_test  = pd.read_parquet('../datasets/01_german/samples/y_test.parquet').target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff79df1-8826-4f05-918e-03652f8a036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheq_acc',\n",
       " 'cred_hist',\n",
       " 'purp',\n",
       " 'save_acc',\n",
       " 'empl_t',\n",
       " 'pers_status',\n",
       " 'guarant_flg',\n",
       " 'prop',\n",
       " 'inst_plan',\n",
       " 'house',\n",
       " 'job',\n",
       " 'tel_flg',\n",
       " 'foreign_flg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../datasets/01_german/factors.json') as json_file:\n",
    "    factors_dict = json.load(json_file)\n",
    "\n",
    "factors_dict['cat_vals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58540fea-e6ce-462c-8427-30f443126065",
   "metadata": {},
   "source": [
    "## 3. Define Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773fea9-9067-4d91-a30d-4594eb5a3716",
   "metadata": {},
   "source": [
    "All the modules that might be part of the pipeline should be defined below (or import them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3c5e57-7b87-420b-b5a8-8bcedade03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineWithReferenceFeature_adj():\n",
    "    \"\"\"\n",
    "    Обертка вокруг CombineWithReferenceFeature()\n",
    "    Позволяет не устанавливать параметры\n",
    "    + variables_to_combine\n",
    "    + reference_variables\n",
    "    заранее (иначе не будет работать с OneHotEncoder\n",
    "    и прочими преобразователями данных, а делать это при .fit()\n",
    "    \"\"\"\n",
    "    def __init__(self, operations):\n",
    "        self.operations = operations\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.combinator = CombineWithReferenceFeature(\n",
    "            variables_to_combine = list(X.columns),\n",
    "            reference_variables = list(X.columns),\n",
    "            operations = self.operations\n",
    "        )\n",
    "        self.combinator.fit(X, y)\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return(self.combinator.transform(X))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4719df0-4d13-4177-b6f8-1af8f91ffc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionReducer():\n",
    "    \"\"\"\n",
    "    Обертка нужна:\n",
    "    1. Чтобы не заменять фичи, а добавлять их к исходному df\n",
    "    2. Для PCA ouput = np.array, требуется заменить на pd.DataFrame \n",
    "    \"\"\"\n",
    "    def __init__(self, gen_class, **kwargs):\n",
    "        self.reducer = gen_class(**kwargs)\n",
    "        # self.reducer.set_params()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.reducer.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # potentially \n",
    "        return pd.concat([X, pd.DataFrame(self.reducer.transform(X), index = X.index)], axis=1)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.reducer.set_params(**kwargs)\n",
    "        return self     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2260b472-260b-4716-a2b3-eda7e0910baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Union\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# from feature_engine.encoding.base_encoder import BaseCategoricalTransformer\n",
    "# from feature_engine.validation import _return_tags\n",
    "# from feature_engine.variable_manipulation import _check_input_parameter_variables\n",
    "\n",
    "class WoEEncoder_adj(BaseCategoricalTransformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        variables: Union[None, int, str, List[Union[str, int]]] = None,\n",
    "        ignore_format: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        if not isinstance(ignore_format, bool):\n",
    "            raise ValueError(\"ignore_format takes only booleans True and False\")\n",
    "\n",
    "        self.variables = _check_input_parameter_variables(variables)\n",
    "        self.ignore_format = ignore_format\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Learn the WoE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas dataframe of shape = [n_samples, n_features]\n",
    "            The training input samples.\n",
    "            Can be the entire dataframe, not just the categorical variables.\n",
    "        y: pandas series.\n",
    "            Target, must be binary.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._check_fit_input_and_variables(X)\n",
    "\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        # check that y is binary\n",
    "        if y.nunique() != 2:\n",
    "            raise ValueError(\n",
    "                \"This encoder is designed for binary classification. The target \"\n",
    "                \"used has more than 2 unique values.\"\n",
    "            )\n",
    "\n",
    "        temp = pd.concat([X, y], axis=1)\n",
    "        temp.columns = list(X.columns) + [\"target\"]\n",
    "\n",
    "        # if target does not have values 0 and 1, we need to remap, to be able to\n",
    "        # compute the averages.\n",
    "        if any(x for x in y.unique() if x not in [0, 1]):\n",
    "            temp[\"target\"] = np.where(temp[\"target\"] == y.unique()[0], 0, 1)\n",
    "\n",
    "        self.encoder_dict_ = {}\n",
    "\n",
    "        total_pos = temp[\"target\"].sum()\n",
    "        total_neg = len(temp) - total_pos\n",
    "        temp[\"non_target\"] = np.where(temp[\"target\"] == 1, 0, 1)\n",
    "\n",
    "        for var in self.variables_:\n",
    "            pos = (temp.groupby([var])[\"target\"].sum() + .5) / total_pos\n",
    "            neg = (temp.groupby([var])[\"non_target\"].sum() + .5) / total_neg\n",
    "\n",
    "            t = pd.concat([pos, neg], axis=1)\n",
    "            t[\"woe\"] = np.log(t[\"target\"] / t[\"non_target\"])\n",
    "\n",
    "            # we make an adjustment to override this error\n",
    "            # if (\n",
    "            #     not t.loc[t[\"target\"] == 0, :].empty\n",
    "            #     or not t.loc[t[\"non_target\"] == 0, :].empty\n",
    "            # ):\n",
    "            #     raise ValueError(\n",
    "            #         \"The proportion of one of the classes for a category in \"\n",
    "            #         \"variable {} is zero, and log of zero is not defined\".format(var)\n",
    "            #     )\n",
    "\n",
    "            self.encoder_dict_[var] = t[\"woe\"].to_dict()\n",
    "\n",
    "        self._check_encoding_dictionary()\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Ugly work around to import the docstring for Sphinx, otherwise not necessary\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    transform.__doc__ = BaseCategoricalTransformer.transform.__doc__\n",
    "\n",
    "    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = super().inverse_transform(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    inverse_transform.__doc__ = BaseCategoricalTransformer.inverse_transform.__doc__\n",
    "\n",
    "    def _more_tags(self):\n",
    "        tags_dict = _return_tags()\n",
    "        # in the current format, the tests are performed using continuous np.arrays\n",
    "        # this means that when we encode some of the values, the denominator is 0\n",
    "        # and this the transformer raises an error, and the test fails.\n",
    "        # For this reason, most sklearn transformers will fail. And it has nothing to\n",
    "        # do with the class not being compatible, it is just that the inputs passed\n",
    "        # are not suitable\n",
    "        tags_dict[\"_skip_test\"] = True\n",
    "        return tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22dc81ed-dce6-4a74-a8cd-549a82b69ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WoE_module = WoEEncoder_adj(variables = factors_dict['cat_vals'])\n",
    "\n",
    "OneHot_module = OneHotEncoder(variables = factors_dict['cat_vals'])\n",
    "\n",
    "PCA_module = DimensionReducer(\n",
    "    gen_class = sklearn.decomposition.PCA,\n",
    "    n_components = 2,    # сколько оставить компонентов; по дефолту - все\n",
    "    whiten = False,      # отключаем whitening - декорреляцию фичей\n",
    "    svd_solver = \"full\", # детали SVD преобразования, за подробностями см. доки\n",
    ")\n",
    "\n",
    "kPCA_module = DimensionReducer(\n",
    "    gen_class = sklearn.decomposition.KernelPCA,\n",
    "    n_components = 8,  # сколько оставить компонентов; по дефолту - все\n",
    "    kernel = \"linear\", # ядро. По дфеолту линейное. Можно сделать своё, но тогда его нужно предварительно вычислить отдельно,\n",
    "                       # поставить kernel = \"precomputed\" и передать уже вычисленное ядро в качестве X\n",
    "    degree = 3,        # степень полинома для некоторых типов ядер. Важный параметр для тьюнинга, но сильно напрягает процессор\n",
    "    n_jobs = -1        # объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "Isomap_module = DimensionReducer(\n",
    "    gen_class = sklearn.manifold.Isomap,\n",
    "    n_neighbors = 5, #количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2,  #сколько оставить компонент; по дефолту - 2\n",
    "    path_method = \"auto\", #алгоритм, который вычисляет кратчайший путь. Варианты см. на странице функции. Этот подбирает сам.\n",
    "    neighbors_algorithm = \"auto\", #алгоритм, который ищет соседей. Инстанс класса NearestNeighbours\n",
    "    n_jobs = -1 #объект умеет быть многопоточным! -1 займет все ядра\n",
    ")\n",
    "\n",
    "UMAP_module = DimensionReducer(\n",
    "    gen_class = umap.UMAP,\n",
    "    n_neighbors = 5,  # количество соседей при вычислении KNN. Основной гиперпараметр, кстати (!!!)\n",
    "    n_components = 2, # сколько оставить компонентов; по дефолту - 2\n",
    "    min_dist = 0.1    # минимальная дистанция, которую можно сохранять между точками в получающемся пространстве. \n",
    "    # Гиперпараметр. При увеличении начинает лучше улавливать общую структуру, но хуже - локальную\n",
    ")\n",
    "\n",
    "CombWRef_module = CombineWithReferenceFeature_adj(\n",
    "    operations = ['mul']\n",
    ")\n",
    "\n",
    "lgbm_mdl = LGBMClassifier(\n",
    "    num_leaves = 10,\n",
    "    learning_rate = .1,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda = 8,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# Tackling imbalances in target\n",
    "RUS_module    = RandomUnderSampler(random_state = seed)\n",
    "ROS_module    = RandomOverSampler(random_state = seed)\n",
    "SMOTE_module  = SMOTE(random_state = seed)\n",
    "ADASYN_module = ADASYN(random_state = seed)\n",
    "\n",
    "# feature selection\n",
    "SeqFearSel_module = SequentialFeatureSelector(\n",
    "    estimator  = lgbm_mdl,  \n",
    "    # k_features = 5,                                                  \n",
    "    forward    = True,                                                  \n",
    "    floating   = True,                                                \n",
    "    verbose    = 0,\n",
    "    cv         = 5\n",
    ")\n",
    "RecFeatAdd_module = RecursiveFeatureAddition(\n",
    "    lgbm_mdl,\n",
    "    threshold = 0.005\n",
    ")\n",
    "# SelShuffl_module = SelectByShuffling(\n",
    "#     estimator = lgbm_mdl,\n",
    "#     # variables=X.columns.to_list(),                                      # можно задать подмножество\n",
    "#     scoring='roc_auc',                                                  # метрика\n",
    "#     threshold=0.01,                                                     # порог ее снижения\n",
    "#     cv=5,\n",
    "#     random_state=42\n",
    "# )\n",
    "SmartSel_module = SmartCorrelatedSelection(\n",
    "    # variables=X.columns.to_list(),\n",
    "    method=\"pearson\",                # можно взять свою функцию\n",
    "    threshold=0.3,                   # порог корреляции\n",
    "    selection_method=\"variance\",     # из коррелирующих групп выбираем признак с наиб дисперсией\n",
    "    estimator=None,                  # понадобится для selection_method=\"model_performance\"        \n",
    "    cv=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7296aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Далее начинается мой код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12046c50-6419-41a5-add4-99f4329eda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'WoE':         WoE_module,\n",
    "    'OneHot':      OneHot_module,\n",
    "    'PCA':         PCA_module,\n",
    "    'kPCA':        kPCA_module,\n",
    "    'Isomap':      Isomap_module,\n",
    "    'UMAP':        UMAP_module,\n",
    "    'CombWRef':    CombWRef_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    'lgbm':        lgbm_mdl,\n",
    "    'RUS':         RUS_module,      \n",
    "    'ROS':         ROS_module,      \n",
    "    'SMOTE':       SMOTE_module,  \n",
    "    'ADASYN':      ADASYN_module,\n",
    "    'SeqFearSel':  SeqFearSel_module,\n",
    "    'RecFeatAdd':  RecFeatAdd_module,\n",
    "    # 'SelShuffl':   SelShuffl_module,\n",
    "    'SmartSel':    SmartSel_module,\n",
    "    'passthrough' : 'passthrough'      # можно добавить в (не последнюю) ячейку пайплайна, чтобы пропустить ее\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9191776-4f78-43dc-aa59-162abcb164d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Define Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc113da-2803-4158-b23f-685890180303",
   "metadata": {},
   "source": [
    "### 4.1. Структура Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcacdc-9228-4db2-b546-25700f07e8e6",
   "metadata": {},
   "source": [
    "Определим структуру самого пайплайна. Словесное описание:\n",
    "    \n",
    "1. Энкодинг категориальных переменных:\n",
    "    + OneHotEncoder\n",
    "    + WoE\n",
    "3. Feature Engineering:\n",
    "    + PCA\n",
    "    + Kernel PCA\n",
    "    + Isomap\n",
    "    + UMAP\n",
    "    + Combine with Reference (feature multiplication)\n",
    "    + _отсутствует_\n",
    "4. Feature Selection:\n",
    "    + RecursiveFeatureAddition\n",
    "    + SequentialFeatureSelector\n",
    "    + SmartCorrelatedSelection\n",
    "    + _отсутствует_\n",
    "4. Resampling:\n",
    "    + Randomised Undersampling (RUS)\n",
    "    + Randomised Oversampling  (ROS)\n",
    "    + Synthetic Minority Oversampling Technique (SMOTE)\n",
    "    + Adaptive Synthetic (ADASYN)\n",
    "    + _отсутствует_\n",
    "5. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547825ef",
   "metadata": {},
   "source": [
    "Кандидаты для каждого элемента пайплайна (`passthrough` означает, что пропускаем)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47770fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    # 'missing_vals': \n",
    "    'cat_encoding':  ['OneHot', 'WoE'], # , 'woe' пропустить нельзя из-за наличия кат. пер-х\n",
    "    'imbalance':     ['passthrough', 'RUS', 'ROS', 'SMOTE', 'ADASYN'],\n",
    "    'feat_eng':      ['passthrough', 'PCA', 'kPCA', 'Isomap', 'UMAP'], # , 'CombWRef' # удалил, т.к. долго считается\n",
    "    'feat_sel':      ['passthrough', 'SeqFearSel', 'RecFeatAdd', 'SmartSel'], # 'SelShuffl' is omitted, since it might drop all Xs\n",
    "    'lgbm':          ['lgbm']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ba8bd",
   "metadata": {},
   "source": [
    "Функции для выбора гиперпараметров для отдельных элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc1fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_params(trial) -> dict:\n",
    "    return {\n",
    "        \"n_components\" : trial.suggest_int(\"PCA__n_components\", 2, 11),\n",
    "        \"whiten\" : trial.suggest_categorical(\n",
    "            \"PCA__whiten\",\n",
    "            [True, False]\n",
    "            ),\n",
    "        \"svd_solver\" : trial.suggest_categorical(\n",
    "            \"PCA__svd_solver\",\n",
    "            ['full', 'arpack', 'auto', 'randomized']\n",
    "            )\n",
    "    }\n",
    "\n",
    "def kPCA_params(trial):\n",
    "    return {\n",
    "        \"n_components\" : trial.suggest_int(\"kPCA__n_components\", 5, 11),\n",
    "        \"kernel\" : trial.suggest_categorical(\n",
    "            \"kPCA__kernel\",\n",
    "            ['linear', 'poly', 'rbf', 'sigmoid', 'cosine', 'precomputed']\n",
    "            ),\n",
    "    }\n",
    "\n",
    "def Isomap_params(trial):\n",
    "    return {\n",
    "        \"n_neighbors\" : trial.suggest_int(\"Isomap__n_neighbors\", 2, 11),\n",
    "        \"n_components\" : trial.suggest_int(\"Isomap__n_components\", 2, 5),\n",
    "        \"path_method\" : trial.suggest_categorical(\n",
    "            \"Isomap__path_method\",\n",
    "            ['auto', 'FW', 'D']\n",
    "            )\n",
    "    }\n",
    "\n",
    "def UMAP_params(trial):\n",
    "    return {\n",
    "        \"n_neighbors\" : trial.suggest_int(\"UMAP__n_neighbors\", 2, 11),\n",
    "        \"n_components\" : trial.suggest_int(\"UMAP__n_components\", 2, 11),\n",
    "        \"min_dist\" : trial.suggest_float(\"UMAP__min_dist\", 0.05, 1, step=0.05)\n",
    "    }\n",
    "\n",
    "def LightGBM_params(trial):\n",
    "    return {\n",
    "        \"learning_rate\" : trial.suggest_float(\"LightGBM__learning_rate\", 0.05, 0.31, step=0.05),\n",
    "        \"num_leaves\" : trial.suggest_int(\"LightGBM__num_leaves\", 5, 16),\n",
    "        \"reg_alpha\" : trial.suggest_int(\"LightGBM__reg_alpha\", 0, 16),\n",
    "        \"reg_lambda\" : trial.suggest_int(\"LightGBM__reg_lambda\", 0, 0.16),\n",
    "        \"n_estimators\" : 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354281c",
   "metadata": {},
   "source": [
    "Сложим их в словарик и подадим его на вход оптимизируемой функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b710156-03b3-4e15-9b8f-3d1056037741",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_hparams = {\n",
    "    'PCA' : PCA_params,\n",
    "    'kPCA' : kPCA_params,\n",
    "    'UMAP' : UMAP_params,\n",
    "    'LightGBM' : LightGBM_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe3069",
   "metadata": {},
   "source": [
    "Оптимизиуемая функция. Должна принимать на вход объект `trial` и возвращать значение метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41ac736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, modules, pipe_params, modules_hparams):\n",
    "    pipeline = []\n",
    "    \n",
    "    # выбираем модули и параметры к ним\n",
    "    for elem, options in pipe_params.items():                                    # итерация по парам (ключ, значение) словаря\n",
    "        choice : str = trial.suggest_categorical(f\"pipe__{elem}\", options)       # выбираем элемент пайплайна\n",
    "        module = modules[choice]                                                 # достаем этот объект из словаря\n",
    "\n",
    "        if choice in modules_hparams.keys():                                     # если мы также оптимизируем гиперпараметры для элемента пайплайна\n",
    "            hp_function : callable = modules_hparams[choice]                     # функция, которая возвращает гиперпараметры\n",
    "            hp_choice : dict = hp_function(trial)                                # конкретный набор, который она вернула\n",
    "            module.set_params(**hp_choice)\n",
    "\n",
    "        pipeline.append(\n",
    "            (choice, module)\n",
    "        )\n",
    "    \n",
    "    pipeline = Pipeline(pipeline)                                                # получаем модель\n",
    "\n",
    "    # далее как-то оцениваем качество получившейся модели\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict_proba(X_test)[:, 1]\n",
    "    metric = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f558f05",
   "metadata": {},
   "source": [
    "Собственно запуск оптимизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0659b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-09 21:48:32,529]\u001b[0m A new study created in memory with name: no-name-0ca632e5-a60a-4c8d-8a04-1db70d88949f\u001b[0m\n",
      "\u001b[32m[I 2022-01-09 21:48:36,342]\u001b[0m Trial 0 finished with value: 0.7811636013943983 and parameters: {'pipe__cat_encoding': 'WoE', 'pipe__imbalance': 'SMOTE', 'pipe__feat_eng': 'PCA', 'PCA__n_components': 5, 'PCA__whiten': False, 'PCA__svd_solver': 'arpack', 'pipe__feat_sel': 'RecFeatAdd', 'pipe__lgbm': 'lgbm'}. Best is trial 0 with value: 0.7811636013943983.\u001b[0m\n",
      "\u001b[32m[I 2022-01-09 21:48:57,074]\u001b[0m Trial 1 finished with value: 0.6642625315542733 and parameters: {'pipe__cat_encoding': 'WoE', 'pipe__imbalance': 'RUS', 'pipe__feat_eng': 'UMAP', 'UMAP__n_neighbors': 8, 'UMAP__n_components': 9, 'UMAP__min_dist': 0.55, 'pipe__feat_sel': 'passthrough', 'pipe__lgbm': 'lgbm'}. Best is trial 0 with value: 0.7811636013943983.\u001b[0m\n",
      "\u001b[32m[I 2022-01-09 21:49:08,782]\u001b[0m Trial 2 finished with value: 0.7622911407621109 and parameters: {'pipe__cat_encoding': 'OneHot', 'pipe__imbalance': 'ADASYN', 'pipe__feat_eng': 'passthrough', 'pipe__feat_sel': 'RecFeatAdd', 'pipe__lgbm': 'lgbm'}. Best is trial 0 with value: 0.7811636013943983.\u001b[0m\n",
      "\u001b[32m[I 2022-01-09 21:49:15,357]\u001b[0m Trial 3 finished with value: 0.7157110229594904 and parameters: {'pipe__cat_encoding': 'OneHot', 'pipe__imbalance': 'SMOTE', 'pipe__feat_eng': 'PCA', 'PCA__n_components': 7, 'PCA__whiten': True, 'PCA__svd_solver': 'auto', 'pipe__feat_sel': 'SeqFearSel', 'pipe__lgbm': 'lgbm'}. Best is trial 0 with value: 0.7811636013943983.\u001b[0m\n",
      "\u001b[32m[I 2022-01-09 21:49:19,452]\u001b[0m Trial 4 finished with value: 0.7854309412188965 and parameters: {'pipe__cat_encoding': 'WoE', 'pipe__imbalance': 'SMOTE', 'pipe__feat_eng': 'PCA', 'PCA__n_components': 8, 'PCA__whiten': False, 'PCA__svd_solver': 'auto', 'pipe__feat_sel': 'RecFeatAdd', 'pipe__lgbm': 'lgbm'}. Best is trial 4 with value: 0.7854309412188965.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    func=lambda trial: objective(trial, modules, pipe_params, modules_hparams),  # оптимизируемая функция\n",
    "    n_trials=5,                                                                  # число попыток\n",
    "    timeout=600                                                                  # лимит по времени\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f467845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipe__cat_encoding': 'WoE',\n",
       " 'pipe__imbalance': 'SMOTE',\n",
       " 'pipe__feat_eng': 'PCA',\n",
       " 'PCA__n_components': 8,\n",
       " 'PCA__whiten': False,\n",
       " 'PCA__svd_solver': 'auto',\n",
       " 'pipe__feat_sel': 'RecFeatAdd',\n",
       " 'pipe__lgbm': 'lgbm'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04dbcfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=4, values=[0.7854309412188965], datetime_start=datetime.datetime(2022, 1, 9, 21, 49, 15, 357238), datetime_complete=datetime.datetime(2022, 1, 9, 21, 49, 19, 436425), params={'pipe__cat_encoding': 'WoE', 'pipe__imbalance': 'SMOTE', 'pipe__feat_eng': 'PCA', 'PCA__n_components': 8, 'PCA__whiten': False, 'PCA__svd_solver': 'auto', 'pipe__feat_sel': 'RecFeatAdd', 'pipe__lgbm': 'lgbm'}, distributions={'pipe__cat_encoding': CategoricalDistribution(choices=('OneHot', 'WoE')), 'pipe__imbalance': CategoricalDistribution(choices=('passthrough', 'RUS', 'ROS', 'SMOTE', 'ADASYN')), 'pipe__feat_eng': CategoricalDistribution(choices=('passthrough', 'PCA', 'kPCA', 'Isomap', 'UMAP')), 'PCA__n_components': IntUniformDistribution(high=11, low=2, step=1), 'PCA__whiten': CategoricalDistribution(choices=(True, False)), 'PCA__svd_solver': CategoricalDistribution(choices=('full', 'arpack', 'auto', 'randomized')), 'pipe__feat_sel': CategoricalDistribution(choices=('passthrough', 'SeqFearSel', 'RecFeatAdd', 'SmartSel')), 'pipe__lgbm': CategoricalDistribution(choices=('lgbm',))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=4, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa1c9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854309412188965"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "maa-automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
